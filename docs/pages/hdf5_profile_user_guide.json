{
    "url": "https://slurm.schedmd.com/hdf5_profile_user_guide.html",
    "sections": [
        {
            "title": "\n\nSlurm Workload Manager\n\n",
            "content": "\n\nSchedMD\n\n"
        },
        {
            "title": "Profiling Using HDF5 User Guide",
            "content": "Contents\nOverview\nAdministration\nProfiling Jobs\nHDF5\nData Structure\nOverviewThe acct_gather_profile/hdf5 plugin allows Slurm to coordinate collecting\ndata on jobs it runs on a cluster that is more detailed than is practical to\ninclude in its database. The data comes from periodically sampling various\nperformance data either collected by Slurm, the operating system, or\ncomponent software. The plugin will record the data from each source\nas a Time Series and also accumulate totals for each statistic for\nthe job.Time Series are energy data collected by an acct_gather_energy plugin,\nI/O data from a network interface collected by an acct_gather_interconnect\nplugin, I/O data from parallel file systems such as Lustre collected by an\nacct_gather_filesystem plugin, and task performance data such as local disk I/O,\ncpu consumption, and memory use from a jobacct_gather plugin.\nData from other sources may be added in the future.The data is collected into a file on a shared file system for each step on\neach allocated node of a job and then merged into an HDF5 file.\nIndividual files on a shared file system was chosen because it is possible\nthat the data is voluminous so solutions that pass data to the Slurm control\ndaemon via RPC may not scale to very large clusters or jobs with\nmany allocated nodes.Administration\n\nShared File System\nThe HDF5 Profile Plugin requires a common shared file system on all\nthe compute nodes. While a job is running, the plugin writes a\nfile into this file system for each step of the job on each node. When\nthe job ends, the merge process is launched and the node-step files\nare combined into one HDF5 file for the job.\nThe root of the directory structure is declared in the ProfileHDF5Dir\noption in the acct_gather.conf file. The directory will be created by\nSlurm if it doesn't exist.  Each user will have\ntheir own directory created in the ProfileHDF5Dir which contains\nthe HDF5 files.  All the directories and files are created by the\nSlurmdUser which is usually root. The user specific directories, as well\nas the files inside, are chowned to the user running the job so they\ncan access the files.  Since user root is usually creating these\nfiles/directories a root squashed file system will not work for\nthe ProfileHDF5Dir.\nEach user that creates a profile will have a subdirectory in the profile\ndirectory that has read/write permission only for the user.\nConfiguration parameters\n\n\nThe profile plugin is enabled in the\nslurm.conf file and it is internally\nconfigured in the\nacct_gather.conf file.\n\n\n\nslurm.conf parameters\n\n\n\n\nAcctGatherProfileType=acct_gather_profile/hdf5\nEnables the HDF5 plugin.\nJobAcctGatherFrequency=<seconds>\nSets the sampling frequency for data types.\n\n\n\n\n\nacct_gather.conf parameters\n\n\n\nThese parameters are directly used by the HDF5 Profile Plugin.\n\nProfileHDF5Dir=<path>\nThis parameter is the path to the shared folder into which the\nacct_gather_profile plugin will write detailed data as an HDF5 file.\nThe directory is assumed to be on a file system shared by the controller and\nall compute nodes. This is a required parameter.\nProfileHDF5Default=[options]\nA comma-delimited list of data types to be collected for each job\nsubmission. Use this option with caution. A node-step file will be created on\nevery node for every step of every job. They will not automatically be merged\ninto job files. (Even job files for large numbers of small jobs would fill the\nfile system.) This option is intended for test environments where you\nmight want to profile a series of jobs but do not want to have to\nadd the --profile option to the launch scripts.\nThe options are described below and in the man pages for acct_gather.conf,\nsrun, salloc and sbatch commands.\n\n\n\n\n\nTime Series Control Parameters\n\n\n\nOther plugins add time series data to the HDF5 collection. They typically\nhave a default polling frequency specified in slurm.conf in the\nJobAcctGatherFrequency parameter. The polling frequency can be overridden\nusing the --acctg-freq\nsrun parameter.\nThey are both of the form task=sec,energy=sec,filesystem=sec,network=sec.\nThe IPMI energy plugin also needs the EnergyIPMIFrequency value set\nin the acct_gather.conf file. This sets the rate at which the plugin samples\nthe external sensors. This value should be the same as the energy=sec in\neither JobAcctGatherFrequency or --acctg-freq.\nNote that the IPMI and profile sampling are not synchronous.\nThe profile sample simply takes the last available IPMI sample value.\nIf the profile energy sample is more frequent than the IPMI sample rate,\nthe IPMI value will be repeated. If the profile energy sample is greater\nthan the IPMI rate, IPMI values will be lost.\nAlso note that smallest effective IPMI (EnergyIPMIFrequency) sample rate\nfor 2013 era Intel processors is 3 seconds.\n\n\nProfiling Jobs\n\n\nData Collection\n\n\nThe --profile option on salloc|sbatch|srun  controls whether data is\ncollected and what type of data is collected. If --profile is not specified\nno data collected unless the ProfileHDF5Default\noption is used in acct_gather.conf. --profile on the command line overrides\nany value specified in the configuration file.\n\n\n--profile=<all|none|[energy[,|task[,|filesystem[,|network]]]]>\n\nEnables detailed data collection by the acct_gather_profile plugin.\nDetailed data are typically time-series that are stored in a HDF5 file for\nthe job.\n\n\nAll\nAll data types are collected. (Cannot be combined with other values.)\n\nNone\nNo data types are collected. This is the default. (Cannot be\ncombined with other values.)\n\nEnergy\nEnergy data is collected.\nFilesystem\nFilesystem data is collected. Currently only\nLustre filesystem is supported.\nNetwork\nNetwork (InfiniBand) data is collected.\nTask\nTask (I/O, Memory, ...) data is collected.\n\n\n\n\nData Consolidation\n\n\nThe node-step files are merged into one HDF5 file for the job using the\nsh5util.\nIf the job is started with sbatch, the command line may added to the normal\nlaunch script,  For example:\n\nsbatch -n1 -d$SLURM_JOB_ID --wrap=\"sh5util -j $SLURM_JOB_ID\"\n\nData Extraction\n\n\nThe sh5util program can also be used to extract\nspecific data from the HDF5 file and write it in comma separated value (csv)\nform for importation into other analysis tools such as spreadsheets.\nHDF5\nHDF5 is a well known structured data set that allows heterogeneous but\nrelated data to be stored in one file.\n(.i.e. sections for energy statistics, network I/O, Task data, etc.)\nIts internal structure resembles a\nfile system with groups being similar to directories and\ndata sets being similar to files. It also allows attributes\nto be attached to groups to store application defined properties.\nThere are commodity programs, notably\n\nHDFView, for viewing and manipulating these files.\n\nBelow is a screen shot from HDFView expanding the job tree and showing the\nattributes for a specific task.\n\n\nData Structure\n\n\n\n\n\n\n\nIn the job file, there will be a group for each step of the job.\nWithin each step, there will be a group for nodes, and a group for tasks.\n\n\n\nThe nodes group will have a group for each node in the step allocation.\nFor each node group, there is a sub-group for Time Series and another\nfor Totals.\n\n\nThe Time Series group\ncontains a group/dataset containing the time series for each collector.\n\n\nThe Totals group contains a group/dataset that has corresponding\nMinimum, Average, Maximum, and Sum Total for each item in the time series.\n\n\n\nThe Tasks group will only contain a subgroup for each task.\nIt primarily contains an attribute stating the node on which the task was\nexecuted. This set of groups is essentially a cross reference table.\n\n\n\n\nEnergy Data\nAcctGatherEnergyType=acct_gather_energy/ipmi\nis required in slurm.conf to collect energy data.\nAppropriately set energy=freq in either JobAcctGatherFrequency in slurm.conf\nor in --acctg-freq on the command line.\nAlso appropriately set EnergyIPMIFrequency in acct_gather.conf.\nEach data sample in the Energy Time Series contains the following data items.\n\n\nDate Time\nTime of day at which the data sample was taken. This can be used to\ncorrelate activity with other sources such as logs.\nTime\nElapsed time since the beginning of the step.\nPower\nPower consumption during the interval.\nCPU Frequency\nCPU Frequency at time of sample in kilohertz.\n\nFilesystem Data\n\n\nAcctGatherFilesystemType=acct_gather_filesystem/lustre\nis required in slurm.conf to collect task data.\nAppropriately set Filesystem=freq in either JobAcctGatherFrequency in slurm.conf\nor in --acctg-freq on the command line.\nEach data sample in the Filesystem Time Series contains the following data items.\n\n\nDate Time\nTime of day at which the data sample was taken. This can be used to\ncorrelate activity with other sources such as logs.\nTime\nElapsed time since the beginning of the step.\nReads\nNumber of read operations.\nMegabytes Read\nNumber of megabytes read.\nWrites\nNumber of write operations.\nMegabytes Write\nNumber of megabytes written.\n\nNetwork (Infiniband Data)\n\n\nAcctGatherInterconnectType=acct_gather_interconnect/ofed\nis required in slurm.conf to collect task data.\nAppropriately set network=freq in either JobAcctGatherFrequency in slurm.conf\nor in --acctg-freq on the command line.\nEach data sample in the Network Time Series contains the following\ndata items.\n\nDate Time\nTime of day at which the data sample was taken. This can be used to\ncorrelate activity with other sources such as logs.\nTime\nElapsed time since the beginning of the step.\nPackets In\nNumber of packets coming in.\nMegabytes Read\nNumber of megabytes coming in through the interface.\nPackets Out\nNumber of packets going out.\nMegabytes Write\nNumber of megabytes going out through the interface.\n\nTask Data\nJobAcctGatherType=jobacct_gather/linux\nis required in slurm.conf to collect task data.\nAppropriately set task=freq in either JobAcctGatherFrequency in slurm.conf\nor in --acctg-freq on the command line.\nEach data sample in the Task Time Series contains the following data\nitems.\n\nDate Time\nTime of day at which the data sample was taken. This can be used to\ncorrelate activity with other sources such as logs.\nTime\nElapsed time since the beginning of the step.\nCPU Frequency\nCPU Frequency at time of sample.\nCPU Time\nSeconds of CPU time used during the sample.\nCPU Utilization\nCPU Utilization during the interval.\nRSS\nValue of RSS at time of sample.\nVM Size\nValue of VM Size at time of sample.\nPages\nPages used in sample.\nRead Megabytes\nNumber of megabytes read from local disk.\nWrite Megabytes\nNumber of megabytes written to local disk.\n\nLast modified 17 October 2022\n"
        },
        {
            "title": "Navigation",
            "content": "\nSlurm Workload Manager\nVersion 24.05\n\n\nAbout\n\nOverview\nRelease Notes\n\n\n\nUsing\n\nDocumentation\nFAQ\nPublications\n\n\n\nInstalling\n\nDownload\nRelated Software\nInstallation Guide\n\n\n\nGetting Help\n\nMailing Lists\nSupport and Training\nTroubleshooting\n\n\n"
        },
        {
            "title": "Profiling Jobs\n\n",
            "content": "Data Collection\n\nThe --profile option on salloc|sbatch|srun  controls whether data is\ncollected and what type of data is collected. If --profile is not specified\nno data collected unless the ProfileHDF5Default\noption is used in acct_gather.conf. --profile on the command line overrides\nany value specified in the configuration file.\n\n--profile=<all|none|[energy[,|task[,|filesystem[,|network]]]]>\n\nEnables detailed data collection by the acct_gather_profile plugin.\nDetailed data are typically time-series that are stored in a HDF5 file for\nthe job.\n\n\nAll\nAll data types are collected. (Cannot be combined with other values.)\n\nNone\nNo data types are collected. This is the default. (Cannot be\ncombined with other values.)\n\nEnergy\nEnergy data is collected.\nFilesystem\nFilesystem data is collected. Currently only\nLustre filesystem is supported.\nNetwork\nNetwork (InfiniBand) data is collected.\nTask\nTask (I/O, Memory, ...) data is collected.\n\n\n\nData Consolidation\n\nThe node-step files are merged into one HDF5 file for the job using the\nsh5util.If the job is started with sbatch, the command line may added to the normal\nlaunch script,  For example:\nsbatch -n1 -d$SLURM_JOB_ID --wrap=\"sh5util -j $SLURM_JOB_ID\"\nData Extraction\n\nThe sh5util program can also be used to extract\nspecific data from the HDF5 file and write it in comma separated value (csv)\nform for importation into other analysis tools such as spreadsheets.HDF5HDF5 is a well known structured data set that allows heterogeneous but\nrelated data to be stored in one file.\n(.i.e. sections for energy statistics, network I/O, Task data, etc.)\nIts internal structure resembles a\nfile system with groups being similar to directories and\ndata sets being similar to files. It also allows attributes\nto be attached to groups to store application defined properties.There are commodity programs, notably\n\nHDFView, for viewing and manipulating these files.\n\nBelow is a screen shot from HDFView expanding the job tree and showing the\nattributes for a specific task.\n\n\nData Structure\n\n\n\n\n\n\n\nIn the job file, there will be a group for each step of the job.\nWithin each step, there will be a group for nodes, and a group for tasks.\n\n\n\nThe nodes group will have a group for each node in the step allocation.\nFor each node group, there is a sub-group for Time Series and another\nfor Totals.\n\n\nThe Time Series group\ncontains a group/dataset containing the time series for each collector.\n\n\nThe Totals group contains a group/dataset that has corresponding\nMinimum, Average, Maximum, and Sum Total for each item in the time series.\n\n\n\nThe Tasks group will only contain a subgroup for each task.\nIt primarily contains an attribute stating the node on which the task was\nexecuted. This set of groups is essentially a cross reference table.\n\n\n\n\nEnergy Data\nAcctGatherEnergyType=acct_gather_energy/ipmi\nis required in slurm.conf to collect energy data.\nAppropriately set energy=freq in either JobAcctGatherFrequency in slurm.conf\nor in --acctg-freq on the command line.\nAlso appropriately set EnergyIPMIFrequency in acct_gather.conf.\nEach data sample in the Energy Time Series contains the following data items.\n\n\nDate Time\nTime of day at which the data sample was taken. This can be used to\ncorrelate activity with other sources such as logs.\nTime\nElapsed time since the beginning of the step.\nPower\nPower consumption during the interval.\nCPU Frequency\nCPU Frequency at time of sample in kilohertz.\n\nFilesystem Data\n\n\nAcctGatherFilesystemType=acct_gather_filesystem/lustre\nis required in slurm.conf to collect task data.\nAppropriately set Filesystem=freq in either JobAcctGatherFrequency in slurm.conf\nor in --acctg-freq on the command line.\nEach data sample in the Filesystem Time Series contains the following data items.\n\n\nDate Time\nTime of day at which the data sample was taken. This can be used to\ncorrelate activity with other sources such as logs.\nTime\nElapsed time since the beginning of the step.\nReads\nNumber of read operations.\nMegabytes Read\nNumber of megabytes read.\nWrites\nNumber of write operations.\nMegabytes Write\nNumber of megabytes written.\n\nNetwork (Infiniband Data)\n\n\nAcctGatherInterconnectType=acct_gather_interconnect/ofed\nis required in slurm.conf to collect task data.\nAppropriately set network=freq in either JobAcctGatherFrequency in slurm.conf\nor in --acctg-freq on the command line.\nEach data sample in the Network Time Series contains the following\ndata items.\n\nDate Time\nTime of day at which the data sample was taken. This can be used to\ncorrelate activity with other sources such as logs.\nTime\nElapsed time since the beginning of the step.\nPackets In\nNumber of packets coming in.\nMegabytes Read\nNumber of megabytes coming in through the interface.\nPackets Out\nNumber of packets going out.\nMegabytes Write\nNumber of megabytes going out through the interface.\n\nTask Data\nJobAcctGatherType=jobacct_gather/linux\nis required in slurm.conf to collect task data.\nAppropriately set task=freq in either JobAcctGatherFrequency in slurm.conf\nor in --acctg-freq on the command line.\nEach data sample in the Task Time Series contains the following data\nitems.\n\nDate Time\nTime of day at which the data sample was taken. This can be used to\ncorrelate activity with other sources such as logs.\nTime\nElapsed time since the beginning of the step.\nCPU Frequency\nCPU Frequency at time of sample.\nCPU Time\nSeconds of CPU time used during the sample.\nCPU Utilization\nCPU Utilization during the interval.\nRSS\nValue of RSS at time of sample.\nVM Size\nValue of VM Size at time of sample.\nPages\nPages used in sample.\nRead Megabytes\nNumber of megabytes read from local disk.\nWrite Megabytes\nNumber of megabytes written to local disk.\n\nLast modified 17 October 2022\n"
        },
        {
            "title": "Data Structure\n\n",
            "content": "\n\n\n\n\nIn the job file, there will be a group for each step of the job.\nWithin each step, there will be a group for nodes, and a group for tasks.\n\n\n\nThe nodes group will have a group for each node in the step allocation.\nFor each node group, there is a sub-group for Time Series and another\nfor Totals.\n\n\nThe Time Series group\ncontains a group/dataset containing the time series for each collector.\n\n\nThe Totals group contains a group/dataset that has corresponding\nMinimum, Average, Maximum, and Sum Total for each item in the time series.\n\n\n\nThe Tasks group will only contain a subgroup for each task.\nIt primarily contains an attribute stating the node on which the task was\nexecuted. This set of groups is essentially a cross reference table.\n\n\n\nEnergy DataAcctGatherEnergyType=acct_gather_energy/ipmi\nis required in slurm.conf to collect energy data.\nAppropriately set energy=freq in either JobAcctGatherFrequency in slurm.conf\nor in --acctg-freq on the command line.\nAlso appropriately set EnergyIPMIFrequency in acct_gather.conf.\nEach data sample in the Energy Time Series contains the following data items.\n\n\nDate Time\nTime of day at which the data sample was taken. This can be used to\ncorrelate activity with other sources such as logs.\nTime\nElapsed time since the beginning of the step.\nPower\nPower consumption during the interval.\nCPU Frequency\nCPU Frequency at time of sample in kilohertz.\n\nFilesystem Data\n\n\nAcctGatherFilesystemType=acct_gather_filesystem/lustre\nis required in slurm.conf to collect task data.\nAppropriately set Filesystem=freq in either JobAcctGatherFrequency in slurm.conf\nor in --acctg-freq on the command line.\nEach data sample in the Filesystem Time Series contains the following data items.\n\n\nDate Time\nTime of day at which the data sample was taken. This can be used to\ncorrelate activity with other sources such as logs.\nTime\nElapsed time since the beginning of the step.\nReads\nNumber of read operations.\nMegabytes Read\nNumber of megabytes read.\nWrites\nNumber of write operations.\nMegabytes Write\nNumber of megabytes written.\n\nNetwork (Infiniband Data)\n\n\nAcctGatherInterconnectType=acct_gather_interconnect/ofed\nis required in slurm.conf to collect task data.\nAppropriately set network=freq in either JobAcctGatherFrequency in slurm.conf\nor in --acctg-freq on the command line.\nEach data sample in the Network Time Series contains the following\ndata items.\n\nDate Time\nTime of day at which the data sample was taken. This can be used to\ncorrelate activity with other sources such as logs.\nTime\nElapsed time since the beginning of the step.\nPackets In\nNumber of packets coming in.\nMegabytes Read\nNumber of megabytes coming in through the interface.\nPackets Out\nNumber of packets going out.\nMegabytes Write\nNumber of megabytes going out through the interface.\n\nTask Data\nJobAcctGatherType=jobacct_gather/linux\nis required in slurm.conf to collect task data.\nAppropriately set task=freq in either JobAcctGatherFrequency in slurm.conf\nor in --acctg-freq on the command line.\nEach data sample in the Task Time Series contains the following data\nitems.\n\nDate Time\nTime of day at which the data sample was taken. This can be used to\ncorrelate activity with other sources such as logs.\nTime\nElapsed time since the beginning of the step.\nCPU Frequency\nCPU Frequency at time of sample.\nCPU Time\nSeconds of CPU time used during the sample.\nCPU Utilization\nCPU Utilization during the interval.\nRSS\nValue of RSS at time of sample.\nVM Size\nValue of VM Size at time of sample.\nPages\nPages used in sample.\nRead Megabytes\nNumber of megabytes read from local disk.\nWrite Megabytes\nNumber of megabytes written to local disk.\n\nLast modified 17 October 2022\n"
        },
        {
            "title": "slurm.conf parameters\n\n",
            "content": "\n\nAcctGatherProfileType=acct_gather_profile/hdf5\nEnables the HDF5 plugin.\nJobAcctGatherFrequency=<seconds>\nSets the sampling frequency for data types.\n\n"
        },
        {
            "title": "acct_gather.conf parameters\n\n",
            "content": "\nThese parameters are directly used by the HDF5 Profile Plugin.\n\nProfileHDF5Dir=<path>\nThis parameter is the path to the shared folder into which the\nacct_gather_profile plugin will write detailed data as an HDF5 file.\nThe directory is assumed to be on a file system shared by the controller and\nall compute nodes. This is a required parameter.\nProfileHDF5Default=[options]\nA comma-delimited list of data types to be collected for each job\nsubmission. Use this option with caution. A node-step file will be created on\nevery node for every step of every job. They will not automatically be merged\ninto job files. (Even job files for large numbers of small jobs would fill the\nfile system.) This option is intended for test environments where you\nmight want to profile a series of jobs but do not want to have to\nadd the --profile option to the launch scripts.\nThe options are described below and in the man pages for acct_gather.conf,\nsrun, salloc and sbatch commands.\n\n"
        },
        {
            "title": "Time Series Control Parameters\n\n",
            "content": "\nOther plugins add time series data to the HDF5 collection. They typically\nhave a default polling frequency specified in slurm.conf in the\nJobAcctGatherFrequency parameter. The polling frequency can be overridden\nusing the --acctg-freq\nsrun parameter.\nThey are both of the form task=sec,energy=sec,filesystem=sec,network=sec.\nThe IPMI energy plugin also needs the EnergyIPMIFrequency value set\nin the acct_gather.conf file. This sets the rate at which the plugin samples\nthe external sensors. This value should be the same as the energy=sec in\neither JobAcctGatherFrequency or --acctg-freq.\nNote that the IPMI and profile sampling are not synchronous.\nThe profile sample simply takes the last available IPMI sample value.\nIf the profile energy sample is more frequent than the IPMI sample rate,\nthe IPMI value will be repeated. If the profile energy sample is greater\nthan the IPMI rate, IPMI values will be lost.\nAlso note that smallest effective IPMI (EnergyIPMIFrequency) sample rate\nfor 2013 era Intel processors is 3 seconds.\n"
        },
        {
            "title": "Filesystem Data\n\n",
            "content": "AcctGatherFilesystemType=acct_gather_filesystem/lustre\nis required in slurm.conf to collect task data.\nAppropriately set Filesystem=freq in either JobAcctGatherFrequency in slurm.conf\nor in --acctg-freq on the command line.\nEach data sample in the Filesystem Time Series contains the following data items.\n\n\nDate Time\nTime of day at which the data sample was taken. This can be used to\ncorrelate activity with other sources such as logs.\nTime\nElapsed time since the beginning of the step.\nReads\nNumber of read operations.\nMegabytes Read\nNumber of megabytes read.\nWrites\nNumber of write operations.\nMegabytes Write\nNumber of megabytes written.\n\nNetwork (Infiniband Data)\n\n\nAcctGatherInterconnectType=acct_gather_interconnect/ofed\nis required in slurm.conf to collect task data.\nAppropriately set network=freq in either JobAcctGatherFrequency in slurm.conf\nor in --acctg-freq on the command line.\nEach data sample in the Network Time Series contains the following\ndata items.\n\nDate Time\nTime of day at which the data sample was taken. This can be used to\ncorrelate activity with other sources such as logs.\nTime\nElapsed time since the beginning of the step.\nPackets In\nNumber of packets coming in.\nMegabytes Read\nNumber of megabytes coming in through the interface.\nPackets Out\nNumber of packets going out.\nMegabytes Write\nNumber of megabytes going out through the interface.\n\nTask Data\nJobAcctGatherType=jobacct_gather/linux\nis required in slurm.conf to collect task data.\nAppropriately set task=freq in either JobAcctGatherFrequency in slurm.conf\nor in --acctg-freq on the command line.\nEach data sample in the Task Time Series contains the following data\nitems.\n\nDate Time\nTime of day at which the data sample was taken. This can be used to\ncorrelate activity with other sources such as logs.\nTime\nElapsed time since the beginning of the step.\nCPU Frequency\nCPU Frequency at time of sample.\nCPU Time\nSeconds of CPU time used during the sample.\nCPU Utilization\nCPU Utilization during the interval.\nRSS\nValue of RSS at time of sample.\nVM Size\nValue of VM Size at time of sample.\nPages\nPages used in sample.\nRead Megabytes\nNumber of megabytes read from local disk.\nWrite Megabytes\nNumber of megabytes written to local disk.\n\nLast modified 17 October 2022\n"
        },
        {
            "title": "Network (Infiniband Data)\n\n",
            "content": "AcctGatherInterconnectType=acct_gather_interconnect/ofed\nis required in slurm.conf to collect task data.\nAppropriately set network=freq in either JobAcctGatherFrequency in slurm.conf\nor in --acctg-freq on the command line.\nEach data sample in the Network Time Series contains the following\ndata items.\n\nDate Time\nTime of day at which the data sample was taken. This can be used to\ncorrelate activity with other sources such as logs.\nTime\nElapsed time since the beginning of the step.\nPackets In\nNumber of packets coming in.\nMegabytes Read\nNumber of megabytes coming in through the interface.\nPackets Out\nNumber of packets going out.\nMegabytes Write\nNumber of megabytes going out through the interface.\n\nTask Data\nJobAcctGatherType=jobacct_gather/linux\nis required in slurm.conf to collect task data.\nAppropriately set task=freq in either JobAcctGatherFrequency in slurm.conf\nor in --acctg-freq on the command line.\nEach data sample in the Task Time Series contains the following data\nitems.\n\nDate Time\nTime of day at which the data sample was taken. This can be used to\ncorrelate activity with other sources such as logs.\nTime\nElapsed time since the beginning of the step.\nCPU Frequency\nCPU Frequency at time of sample.\nCPU Time\nSeconds of CPU time used during the sample.\nCPU Utilization\nCPU Utilization during the interval.\nRSS\nValue of RSS at time of sample.\nVM Size\nValue of VM Size at time of sample.\nPages\nPages used in sample.\nRead Megabytes\nNumber of megabytes read from local disk.\nWrite Megabytes\nNumber of megabytes written to local disk.\n\nLast modified 17 October 2022\n"
        },
        {
            "title": "Task Data",
            "content": "JobAcctGatherType=jobacct_gather/linux\nis required in slurm.conf to collect task data.\nAppropriately set task=freq in either JobAcctGatherFrequency in slurm.conf\nor in --acctg-freq on the command line.\nEach data sample in the Task Time Series contains the following data\nitems.\n\nDate Time\nTime of day at which the data sample was taken. This can be used to\ncorrelate activity with other sources such as logs.\nTime\nElapsed time since the beginning of the step.\nCPU Frequency\nCPU Frequency at time of sample.\nCPU Time\nSeconds of CPU time used during the sample.\nCPU Utilization\nCPU Utilization during the interval.\nRSS\nValue of RSS at time of sample.\nVM Size\nValue of VM Size at time of sample.\nPages\nPages used in sample.\nRead Megabytes\nNumber of megabytes read from local disk.\nWrite Megabytes\nNumber of megabytes written to local disk.\n\nLast modified 17 October 2022\n"
        }
    ]
}