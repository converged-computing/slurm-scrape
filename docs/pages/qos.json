{
    "url": "https://slurm.schedmd.com/qos.html",
    "sections": [
        {
            "title": "\n\nSlurm Workload Manager\n\n",
            "content": "\n\nSchedMD\n\n"
        },
        {
            "title": "Quality of Service (QOS)",
            "content": "One can specify a Quality of Service (QOS) for each job submitted\nto Slurm. The QOSs are defined in the Slurm database using the sacctmgr\ncommand. Jobs request a QOS using the \"--qos=\" option to the\nsbatch, salloc, and srun commands.Contents\nEffects on Jobs\n\n Scheduling Priority\n Preemption\n Resource Limits\n\n Partition QOS\n Relative QOS\n Other QOS Options\n Configuration\n Examples\n\nEffects on Jobs\n\nThe QOS associated with a job will affect the job in three key ways:\nscheduling priority, preemption, and resource limits.Job Scheduling Priority\n\nJob scheduling priority is made up of a number of factors as\ndescribed in the priority/multifactor plugin.  One\nof the factors is the QOS priority.  Each QOS is defined in the Slurm\ndatabase and includes an associated priority.  Jobs that request and\nare permitted a QOS will incorporate the priority associated with that\nQOS in the job's multi-factor priority\ncalculation.To enable the QOS priority component of the multi-factor priority\ncalculation, the \"PriorityWeightQOS\" configuration parameter must be\ndefined in the slurm.conf file and assigned an integer value greater\nthan zero. A job's QOS only affects is scheduling priority when the\nmulti-factor plugin is loaded.Job Preemption\n\nSlurm offers two ways for a queued job to preempt a running job,\nfree-up the running job's resources and allocate them to the queued\njob.  See the  Preemption description for\ndetails.The preemption method is determined by the \"PreemptType\"\nconfiguration parameter defined in slurm.conf.  When the \"PreemptType\"\nis set to \"preempt/qos\", a queued job's QOS will be used to determine\nwhether it can preempt a running job. It is important to note that the QOS\nused to determine if a job is eligible for preemption is the QOS associated\nwith the job and not a Partition QOS. The QOS can be assigned (using sacctmgr) a list of other\nQOSs that it can preempt.  When there is a queued job with a QOS that\nis allowed to preempt a running job of another QOS, the Slurm\nscheduler will preempt the running job. The QOS option PreemptExemptTime specifies the minimum run time before the\njob is considered for preemption. The QOS option takes precedence over the\nglobal option of the same name. A Partition QOS with PreemptExemptTime\ntakes precedence over a job QOS with PreemptExemptTime, unless the job QOS\nhas the OverPartQOS flag enabled.Resource LimitsEach QOS is assigned a set of limits which will be applied to the\njob.  The limits mirror the limits imposed by the\nuser/account/cluster/partition association defined in the Slurm\ndatabase and described in the  Resource\nLimits page.  When limits for a QOS have been defined, they\nwill take precedence over the association's limits.Partition QOS\n\nA QOS can be attached to a partition. This means the partition will have all\nthe same limits as the QOS. This does not associate jobs with the QOS, nor does\nit give the job any priority or preemption characteristics of the assigned QOS.\nJobs may separately request the same QOS or a different QOS to gain those\ncharacteristics. However, the Partition QOS limits will override the job's QOS.\nIf the opposite is desired you may configure the job's QOS with\nFlags=OverPartQOS which will reverse the order of precedence.This functionality may be used to implement a true \"floating\"\npartition, in which a partition may access a limited amount of resources with no\nrestrictions on which nodes it uses to get the resources. This is accomplished\nby assigning all nodes to the partition, then configuring a Partition QOS with\nGrpTRES set to the desired resource limits.NOTE: Most QOS attributes are set using the sacctmgr command.\nHowever, setting a QOS as a partition QOS is accomplished in slurm.conf\nthrough the QOS= option in the\nconfiguration of the associated partition. The QOS should be created using\nsacctmgr before it is assigned as a partition QOS.Relative QOS\n\nStarting in Slurm 23.11, a QOS may be configured to contain relative resource\nlimits instead of absolute limits by setting Flags=Relative.\nWhen this flag is set, all resource limits are treated as percentages of the\ntotal resources available. Values higher than 100 are interpreted as 100%.\nMemory limits should be set with no units. Although the default units (MB) will\nbe displayed, the limits will be enforced as a percentage (1MB = 1%).NOTE: When Flags=Relative is added to a QOS, slurmctld\nmust be restarted or reconfigured for the flag to take effect.Generally, the limits on a relative QOS will be calculated relative to the\nresources in the whole cluster. For example, cpu=50 would be\ninterpreted as 50% of all CPUs in the cluster.However, when a relative QOS is also assigned as a partition QOS, some unique\nconditions will apply:\nLimits will be calculated relative to the partition's resources;\nfor example, cpu=50 would be interpreted as 50% of all CPUs in the\nassociated partition.\nOnly one partition may have this QOS as its partition QOS.\nJobs will not be allowed to use it as a normal QOS.\nNOTE: To avoid unexpected job submission errors, it is recommended not\nto add a relative partition QOS to any association-based entities.\n\nOther QOS Options\n\n\nFlags Used by the slurmctld to override or enforce certain\ncharacteristics. To clear a previously set value use the modify command with a\nnew value of -1.\nValid options are:\n\n\nDenyOnLimit If set, jobs using this QOS will be rejected at\nsubmission time if they do not conform to the QOS 'Max' limits as\nstand-alone jobs.\nJobs that go over these limits when other jobs are considered, but conform\nto the limits when considered individually will not be rejected. Instead they\nwill pend until resources are available (as by default without DenyOnLimit).\nGroup limits (e.g. GrpTRES) will also be treated like 'Max' limits\n(e.g. MaxTRESPerNode) and jobs will be denied if they would violate the\nlimit as stand-alone jobs.\nThis currently only applies to QOS and Association limits.\nEnforceUsageThreshold If set, and the QOS also has a UsageThreshold,\nany jobs submitted with this QOS that fall below the UsageThreshold\nwill be held until their Fairshare Usage goes above the Threshold.\nNoDecay If set, this QOS will not have its GrpTRESMins,\nGrpWall and UsageRaw decayed by the slurm.conf PriorityDecayHalfLife\nor PriorityUsageResetPeriod settings.  This allows\na QOS to provide aggregate limits that, once consumed, will not be\nreplenished automatically.  Such a QOS will act as a time-limited quota\nof resources for an association that has access to it.  Account/user\nusage will still be decayed for associations using the QOS.  The QOS\nGrpTRESMins and GrpWall limits can be increased or\nthe QOS RawUsage value reset to 0 (zero) to again allow jobs submitted\nwith this QOS to run (if pending with QOSGrp{TRES}MinutesLimit or\nQOSGrpWallLimit reasons, where {TRES} is some type of trackable resource).\nNoReserve If this flag is set and backfill scheduling is used,\njobs using this QOS will not reserve resources in the backfill\nschedule's  map of resources allocated through time. This flag is\nintended for use with a QOS that may be preempted by jobs associated\nwith all other QOS (e.g use with a \"standby\" QOS). If this flag is\nused with a QOS which can not be preempted by all other QOS, it could\nresult in starvation of larger jobs.\nOverPartQOS If set, jobs using this QOS will be able to\noverride any limits used by the requested partition's QOS limits.\nPartitionMaxNodes If set, jobs using this QOS will be able to\noverride the requested partition's MaxNodes limit.\nPartitionMinNodes If set, jobs using this QOS will be able to\noverride the requested partition's MinNodes limit.\nPartitionTimeLimit If set, jobs using this QOS will be able to\noverride the requested partition's TimeLimit.\nRelative If set, the QOS limits will be treated as percentages of\nthe cluster or partition instead of absolute limits (numbers should be less than\n100). The controller should be restarted or reconfigured after adding the\nRelative flag to the QOS.\nIf this is used as a partition QOS:\n\nLimits will be calculated relative to the partition's resources.\nOnly one partition may have this QOS as its partition QOS.\nJobs will not be allowed to use it as a normal QOS.\n\nRequiresReservation If set, jobs using this QOS must designate a\nreservation when submitting a job.  This option can be useful in\nrestricting usage of a QOS that may have greater preemptive capability\nor additional resources to be allowed only within a reservation.\nUsageFactorSafe If set, and AccountingStorageEnforce includes\nSafe, jobs will only be able to run if the job can run to completion\nwith the UsageFactor applied.\n\n\nGraceTime Preemption grace time to be extended to a job\n  which has been selected for preemption.\nUsageFactor\nA float that is factored into a job's TRES usage (e.g. RawUsage, TRESMins,\nTRESRunMins). For example, if the usagefactor was 2, for every TRESBillingUnit\nsecond a job ran it would count for 2. If the usagefactor was .5, every second\nwould only count for half of the time. A setting of 0 would add no timed usage\nfrom the job.\n\n\nThe usage factor only applies to the job's QOS and not the partition QOS.\n\n\nIf the UsageFactorSafe flag is set and\nAccountingStorageEnforce includes Safe, jobs will only be\nable to run if the job can run to completion with the UsageFactor\napplied.\n\n\nIf the UsageFactorSafe flag is not set and\nAccountingStorageEnforce includes Safe, a job will be able to be\nscheduled without the UsageFactor applied and will be able to run\nwithout being killed due to limits.\n\n\nIf the UsageFactorSafe flag is not set and\nAccountingStorageEnforce does not include Safe, a job will be\nable to be scheduled without the UsageFactor applied and could be killed\ndue to limits.\n\n\nSee AccountingStorageEnforce in slurm.conf man page.\n\n\nDefault is 1. To clear a previously set value use the modify command with a new\nvalue of -1.\n\nUsageThreshold\nA float representing the lowest fairshare of an association allowable\nto run a job.  If an association falls below this threshold and has\npending jobs or submits new jobs those jobs will be held until the\nusage goes back above the threshold.  Use sshare to see current\nshares on the system.\nConfiguration To summarize the above, the QOSs and their associated limits are\ndefined in the Slurm database using the sacctmgr utility.  The\nQOS will only influence job scheduling priority when the multi-factor\npriority plugin is loaded and a non-zero \"PriorityWeightQOS\" has been\ndefined in the slurm.conf file.  The QOS will only determine job\npreemption when the \"PreemptType\" is defined as \"preempt/qos\" in the\nslurm.conf file.  Limits defined for a QOS (and described above) will\noverride the limits of the user/account/cluster/partition\nassociation.QOS examplesQOS manipulation examples. All QOS operations are done using\nthe sacctmgr command. The default output of 'sacctmgr show qos' is\nvery long given the large number of limits and options available\nso it is best to use the format option which filters the display.By default when a cluster is added to the database a default\nqos named normal is created.\n$ sacctmgr show qos format=name,priority\n      Name   Priority\n---------- ----------\n    normal          0\nAdd a new QOS\n$ sacctmgr add qos zebra\n Adding QOS(s)\n  zebra\n Settings\n  Description    = QOS Name\n\n$ sacctmgr show qos format=name,priority\n      Name   Priority\n---------- ----------\n    normal          0\n     zebra          0\nSet QOS priority\n$ sacctmgr modify qos zebra set priority=10\n Modified qos...\n  zebra\n\n$ sacctmgr show qos format=name,priority\n      Name   Priority\n---------- ----------\n    normal          0\n     zebra         10\nSet some other limits\n$ sacctmgr modify qos zebra set GrpTRES=cpu=24\n Modified qos...\n  zebra\n\n$ sacctmgr show qos format=name,priority,GrpTRES\n      Name   Priority       GrpTRES\n---------- ---------- -------------\n    normal          0\n     zebra         10        cpu=24\nAdd a QOS to a user account\n$ sacctmgr modify user crock set qos=zebra\n\n$ sacctmgr show assoc format=cluster,user,qos\n   Cluster       User                  QOS\n---------- ---------- --------------------\ncanis_major                          normal\ncanis_major      root                normal\ncanis_major                          normal\ncanis_major     crock                zebra\nUsers can belong to multiple QOSs\n$ sacctmgr modify user crock set qos+=alligator\n$ sacctmgr show assoc format=cluster,user,qos\n   Cluster       User                  QOS\n---------- ---------- --------------------\ncanis_major                          normal\ncanis_major      root                normal\ncanis_major                          normal\ncanis_major     crock       alligator,zebra\n\nFinally, delete a QOS\n$ sacctmgr delete qos alligator\n Deleting QOS(s)...\n  alligator\nLast modified 22 April 2023"
        },
        {
            "title": "Navigation",
            "content": "\nSlurm Workload Manager\nVersion 24.05\n\n\nAbout\n\nOverview\nRelease Notes\n\n\n\nUsing\n\nDocumentation\nFAQ\nPublications\n\n\n\nInstalling\n\nDownload\nRelated Software\nInstallation Guide\n\n\n\nGetting Help\n\nMailing Lists\nSupport and Training\nTroubleshooting\n\n\n"
        }
    ]
}