{
    "url": "https://slurm.schedmd.com/release_notes.html",
    "sections": [
        {
            "title": "\n\nSlurm Workload Manager\n\n",
            "content": "\n\nSchedMD\n\n"
        },
        {
            "title": "Release Notes",
            "content": "\nThe following are the contents of the RELEASE_NOTES file as distributed\nwith the Slurm source code for this release. Please refer to the NEWS include\nalongside the source as well for more detailed descriptions of the associated\nchanges, and for bugs fixed within each maintenance release.\n\nRELEASE NOTES FOR SLURM VERSION 24.05\n\nIMPORTANT NOTES:\nIf using the slurmdbd (Slurm DataBase Daemon) you must update this first.\n\nNOTE: If using a backup DBD you must start the primary first to do any\ndatabase conversion, the backup will not start until this has happened.\n\nThe 24.05 slurmdbd will work with Slurm daemons of version 23.02 and above.\nYou will not need to update all clusters at the same time, but it is very\nimportant to update slurmdbd first and having it running before updating\nany other clusters making use of it.\n\nSlurm can be upgraded from version 23.02 or 23.11 to version 24.05 without loss\nof jobs or other state information. Upgrading directly from an earlier version\nof Slurm will result in loss of state information.\n\nAll SPANK plugins must be recompiled when upgrading from any Slurm version\nprior to 24.05.\n\nHIGHLIGHTS\n==========\n -- Remove support for Cray XC (\"cray_aries\") systems.\n -- Federation - allow client command operation when slurmdbd is unavailable.\n -- burst_buffer/lua - Added two new hooks: slurm_bb_test_data_in and\n    slurm_bb_test_data_out. The syntax and use of the new hooks are documented\n    in etc/burst_buffer.lua.example. These are required to exist. slurmctld now\n    checks on startup if the burst_buffer.lua script loads and contains all\n    required hooks; slurmctld will exit with a fatal error if this is not\n    successful. Added PollInterval to burst_buffer.conf. Removed the arbitrary\n    limit of 512 copies of the script running simultaneously.\n -- Add QOS limit MaxTRESRunMinsPerAccount.\n -- Add QOS limit MaxTRESRunMinsPerUser.\n -- Add ELIGIBLE environment variable to jobcomp/script plugin.\n -- Always use the QOS name for SLURM_JOB_QOS environment variables.\n    Previously the batch environment would use the description field,\n    which was usually equivalent to the name.\n -- cgroup/v2 - Require dbus-1 version >= 1.11.16.\n -- Allow NodeSet names to be used in SuspendExcNodes.\n -- SuspendExcNodes=:N now counts allocated nodes in N. The first N\n    powered up nodes in  are protected from being suspended.\n -- Store job output, input and error paths in SlurmDBD.\n -- Add USER_DELETE reservation flag to allow users with access to a reservation\n    to delete it.\n -- Add SlurmctldParameters=enable_stepmgr to enable step management through\n    the slurmstepd instead of the controller.\n -- Added PrologFlags=RunInJob to make prolog and epilog run inside the job\n    extern step to include it in the job's cgroup.\n -- Add ability to reserve MPI ports at the job level for stepmgr jobs and\n    subdivide them at the step level.\n -- slurmrestd - Add --generate-openapi-spec argument.\n\nCONFIGURATION FILE CHANGES (see appropriate man page for details)\n=====================================================================\n -- CoreSpecPlugin has been removed.\n -- Removed TopologyPlugin tree and dragonfly support from select/linear.\n    If those topology plugins are desired please switch to select/cons_tres.\n -- Changed the default value for UnkillableStepTimeout to 60 seconds or five\n    times the value of MessageTimeout, whichever is greater.\n -- An error log has been added if JobAcctGatherParams 'UsePss' or 'NoShare' are\n    configured with a plugin other than jobacct_gather/linux. In such case these\n    parameters are ignored.\n -- helpers.conf - Added Flags=rebootless parameter allowing feature changes\n    without rebooting compute nodes.\n -- topology/block - Replaced the BlockLevels with BlockSizes in topology.conf.\n -- Add contain_spank option to SlurmdParameters. When set, spank_user_init(),\n    spank_task_post_fork(), and spank_task_exit() will execute within the\n    job_container/tmpfs plugin namespace.\n -- Add SlurmctldParameters=max_powered_nodes=N, which prevents powering up\n    nodes after the max is reached.\n -- Add ExclusiveTopo to a partition definition in slurm.conf.\n -- Add AccountingStorageParameters=max_step_records to limit how many steps\n    are recorded in the database for each job -- excluding batch, extern, and\n    interactive steps.\n\nCOMMAND CHANGES (see man pages for details)\n===========================================\n -- Add support for \"elevenses\" as an additional time specification.\n -- Add support for sbcast --preserve when job_container/tmpfs configured\n    (previously documented as unsupported).\n -- scontrol - Add new subcommand 'power' for node power control.\n -- squeue - Adjust StdErr, StdOut, and StdIn output formats. These will now\n    consistently print \"(null)\" if a value is unavailable. StdErr will no\n    longer display StdOut if it is not distinctly set. StdOut will now\n    correctly display the default filename pattern for job arrays, and no\n    longer show it for non-batch jobs. However, the expansion patterns will\n    no longer be substituted by default.\n -- Add --segment to job allocation to be used in topology/block.\n -- Add --exclusive=topo for use with topology/block.\n -- squeue - Add --expand-patterns option to expand StdErr, StdOut, StdIn\n    filename patterns as best as possible.\n -- sacct - Add --expand-patterns option to expand StdErr, StdOut, StdIn\n    filename patterns as best as possible.\n -- sreport - Requesting format=Planned will now return the expected Planned\n    time as documented, instead of PlannedDown. To request Planned Down,\n    one must use now format=PLNDDown or format=PlannedDown explicitly. The\n    abbreviations \"Pl\" or \"Pla\" will now make reference to Planned instead of\n    PlannedDown.\n\nAPI CHANGES\n===========\n -- Removed ListIterator type from .\n -- Removed slurm_xlate_job_id() from \n\nSLURMRESTD CHANGES\n==================\n -- openapi/dbv0.0.38 and openapi/v0.0.38 plugins have been removed.\n -- openapi/dbv0.0.39 and openapi/v0.0.39 plugins have been tagged as\n    deprecated to warn of their removal in the next release.\n -- Changed slurmrestd.service to only listen on TCP socket by default.\n    Environments with existing drop-in units for the service may need\n    further adjustments to work after upgrading.\n -- slurmrestd - Tagged `script` field as deprecated in\n    'POST /slurm/v0.0.41/job/submit' in anticipation of removal in future\n    OpenAPI plugin versions. Job submissions should set the `job.script` (or\n    `jobs[0].script` for HetJobs) fields instead.\n -- slurmrestd - Attempt to automatically convert enumerated string arrays with\n    incoming non-string values into strings. Add warning when incoming value for\n    enumerated string arrays can not be converted to string and silently ignore\n    instead of rejecting entire request. This change affects any endpoint that\n    uses an enunmerated string as given in the OpenAPI specification. An\n    example of this conversion would be to 'POST /slurm/v0.0.41/job/submit' with\n    '.job.exclusive = true'. While the JSON (boolean) true value matches a\n    possible enumeration, it is not the expected \"true\" string. This change\n    automatically converts the (boolean) true to (string) \"true\" avoiding a\n    parsing failure.\n -- slurmrestd - Add 'POST /slurm/v0.0.41/job/allocate' endpoint. This endpoint\n    will create a new job allocation without any steps. The allocation will need\n    to be ended via signaling the job or it will run to the timelimit.\n -- slurmrestd - Allow startup when slurmdbd is not configured and avoid loading\n    slurmdbd specific plugins.\n\nMPI/PMI2 CHANGES\n================\n -- Jobs submitted with the SLURM_HOSTFILE environment variable set implies\n    using an arbitrary distribution. Nevertheless, the logic used in PMI2 when\n    generating their associated PMI_process_mapping values has been changed and\n    will now be the same used for the plane distribution, as if \"-m plane\" were\n    used. This has been changed because the original arbitrary distribution\n    implementation did not account for multiple instances of the same host being\n    present in SLURM_HOSTFILE, providing an incorrect process mapping in such\n    case. This change also enables distributing tasks in blocks when using\n    arbitrary distribution, which was not the case before. This only affects\n    mpi/pmi2 plugin.\n\n"
        },
        {
            "title": "Navigation",
            "content": "\nSlurm Workload Manager\nVersion 24.05\n\n\nAbout\n\nOverview\nRelease Notes\n\n\n\nUsing\n\nDocumentation\nFAQ\nPublications\n\n\n\nInstalling\n\nDownload\nRelated Software\nInstallation Guide\n\n\n\nGetting Help\n\nMailing Lists\nSupport and Training\nTroubleshooting\n\n\n"
        }
    ]
}