{
    "url": "https://slurm.schedmd.com/select_design.html",
    "sections": [
        {
            "title": "\n\nSlurm Workload Manager\n\n",
            "content": "\n\nSchedMD\n\n"
        },
        {
            "title": "Select Plugin Design Guide",
            "content": "OverviewThe select plugin is responsible for selecting compute resources to be\nallocated to a job, plus allocating and deallocating those resources.\nThe select plugin is aware of the systems topology, based upon data structures\nestablished by the topology plugin. It can also over-subscribe resources to\nsupport gang scheduling (time slicing of parallel jobs), if so configured.\nOther architectures would rely upon the select/linear\nor select/cons_tres plugins. The select/linear plugin allocates\nwhole nodes to jobs and is the simplest implementation.\nThe select/cons_tres plugin (cons_tres is an abbreviation for\ntrackable resources) can allocate individual sockets, cores, threads\nor CPUs within a node. It also includes the ability to manage other generic\nresources, such as GPUs.\nThe select/cons_tres plugin is slightly slower than\nselect/linear, but contains far more complex logic.Mode of OperationThe select/linear and select/cons_tres plugins have\nsimilar modes of operation. The obvious difference is that data structures\nin select/linear are node-centric, while those in\nselect/cons_tres contain information at a finer resolution (sockets, cores,\nthreads, or CPUs depending upon the SelectTypeParameters configuration\nparameter). The description below is generic and applies to the above two\nplugin implementations. Note that each of these plugins is able to manage\nmemory allocations. If you need to track other resources, such as GPUs,\nyou should use the select/cons_tres plugin.Per node data structures include memory (configured and allocated),\nGRES (configured and allocated, in a List data structure), plus a flag\nindicating if the node has been allocated using an exclusive option (preventing\nother jobs from being allocated resources on that same node). The other key\ndata structure is used to enforce the per-partition OverSubscribe\nconfiguration parameter and tracks how many jobs have been allocated each\ncompute resource (e.g. CPU) in each\npartition. This data structure is different between the plugins based upon\nthe resolution of the resource allocation (e.g. nodes or CPUs).Most of the logic in the select plugin is dedicated to identifying resources\nto be allocated to a new job. Input to that function includes: a pointer to the\nnew job, a bitmap identifying nodes which could be used, node counts (minimum,\nmaximum, and desired), a count of how many jobs of that partition the job can\nshare resources with, and a list of jobs which can be preempted to initiate the\nnew job. The first phase is to determine of all usable nodes, which nodes\nwould best satisfy the resource requirement. This consists of a best-fit\nalgorithm that groups nodes based upon network topology (if the topology/tree\nplugin is configured) or based upon consecutive nodes (by default). Once the\nbest nodes are identified, resources are accumulated for the new job until its\nresource requirements are satisfied.If the job can not be started with currently available resources, the plugin\nwill attempt to identify jobs which can be preempted in order to initiate the\nnew job. A copy of the current system state will be created including details\nabout all resources and active jobs. Preemptable jobs will then be removed\nfrom this simulated system state until the new job can be initiated. When\nsufficient resources are available for the new job, the jobs actually needing\nto be preempted for its initiation will be preempted (this may be a subset of\nthe jobs whose preemption is simulated).Other functions exist to support suspending jobs, resuming jobs, terminating\njobs, shrinking job allocations, un/packing job state information,\nun/packing node state information, etc. The operation of those functions is\nrelatively straightforward and not detailed here.Last modified 29 January 2024"
        },
        {
            "title": "Navigation",
            "content": "\nSlurm Workload Manager\nVersion 24.05\n\n\nAbout\n\nOverview\nRelease Notes\n\n\n\nUsing\n\nDocumentation\nFAQ\nPublications\n\n\n\nInstalling\n\nDownload\nRelated Software\nInstallation Guide\n\n\n\nGetting Help\n\nMailing Lists\nSupport and Training\nTroubleshooting\n\n\n"
        }
    ]
}