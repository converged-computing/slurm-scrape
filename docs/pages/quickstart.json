{
    "url": "https://slurm.schedmd.com/quickstart.html",
    "sections": [
        {
            "title": "\n\nSlurm Workload Manager\n\n",
            "content": "\n\nSchedMD\n\n"
        },
        {
            "title": "Quick Start User Guide",
            "content": "OverviewSlurm is an open source,\nfault-tolerant, and highly scalable cluster management and job scheduling system\nfor large and small Linux clusters. Slurm requires no kernel modifications for\nits operation and is relatively self-contained. As a cluster workload manager,\nSlurm has three key functions. First, it allocates exclusive and/or non-exclusive\naccess to resources (compute nodes) to users for some duration of time so they\ncan perform work. Second, it provides a framework for starting, executing, and\nmonitoring work (normally a parallel job) on the set of allocated nodes. Finally,\nit arbitrates contention for resources by managing a queue of pending work.ArchitectureAs depicted in Figure 1, Slurm consists of a slurmd daemon running on\neach compute node and a central slurmctld daemon running on a management node\n(with optional fail-over twin).\nThe slurmd daemons provide fault-tolerant hierarchical communications.\nThe user commands include: sacct, sacctmgr, salloc,\nsattach, sbatch, sbcast, scancel, scontrol,\nscrontab, sdiag, sh5util, sinfo, sprio,\nsqueue, sreport, srun, sshare, sstat,\nstrigger and sview.\nAll of the commands can run anywhere in the cluster.\n\n  Figure 1. Slurm components\nThe entities managed by these Slurm daemons, shown in Figure 2, include\nnodes, the compute resource in Slurm,\npartitions, which group nodes into logical (possibly overlapping) sets,\njobs, or allocations of resources assigned to a user for\na specified amount of time, and\njob steps, which are sets of (possibly parallel) tasks within a job.\nThe partitions can be considered job queues, each of which has an assortment of\nconstraints such as job size limit, job time limit, users permitted to use it, etc.\nPriority-ordered jobs are allocated nodes within a partition until the resources\n(nodes, processors, memory, etc.) within that partition are exhausted. Once\na job is assigned a set of nodes, the user is able to initiate parallel work in\nthe form of job steps in any configuration within the allocation. For instance,\na single job step may be started that utilizes all nodes allocated to the job,\nor several job steps may independently use a portion of the allocation.\n\n  Figure 2. Slurm entities\nCommandsMan pages exist for all Slurm daemons, commands, and API functions. The command\noption --help also provides a brief summary of\noptions. Note that the command options are all case sensitive.sacct is used to report job or job\nstep accounting information about active or completed jobs.salloc is used to allocate resources\nfor a job in real time. Typically this is used to allocate resources and spawn a shell.\nThe shell is then used to execute srun commands to launch parallel tasks.sattach is used to attach standard\ninput, output, and error plus signal capabilities to a currently running\njob or job step. One can attach to and detach from jobs multiple times.sbatch is used to submit a job script\nfor later execution. The script will typically contain one or more srun commands\nto launch parallel tasks.sbcast is used to transfer a file\nfrom local disk to local disk on the nodes allocated to a job. This can be\nused to effectively use diskless compute nodes or provide improved performance\nrelative to a shared file system.scancel is used to cancel a pending\nor running job or job step. It can also be used to send an arbitrary signal to\nall processes associated with a running job or job step.scontrol is the administrative tool\nused to view and/or modify Slurm state. Note that many scontrol\ncommands can only be executed as user root.sinfo reports the state of partitions\nand nodes managed by Slurm. It has a wide variety of filtering, sorting, and formatting\noptions.sprio is used to display a detailed\nview of the components affecting a job's priority.squeue reports the state of jobs or\njob steps. It has a wide variety of filtering, sorting, and formatting options.\nBy default, it reports the running jobs in priority order and then the pending\njobs in priority order.srun is used to submit a job for\nexecution or initiate job steps in real time.\nsrun\nhas a wide variety of options to specify resource requirements, including: minimum\nand maximum node count, processor count, specific nodes to use or not use, and\nspecific node characteristics (so much memory, disk space, certain required\nfeatures, etc.).\nA job can contain multiple job steps executing sequentially or in parallel on\nindependent or shared resources within the job's node allocation.sshare displays detailed information\nabout fairshare usage on the cluster. Note that this is only viable when using\nthe priority/multifactor plugin.sstat is used to get information\nabout the resources utilized by a running job or job step.strigger is used to set, get or\nview event triggers. Event triggers include things such as nodes going down\nor jobs approaching their time limit.sview is a graphical user interface to\nget and update state information for jobs, partitions, and nodes managed by Slurm.ExamplesFirst we determine what partitions exist on the system, what nodes\nthey include, and general system state. This information is provided\nby the sinfo command.\nIn the example below we find there are two partitions: debug\nand batch.\nThe * following the name debug indicates this is the\ndefault partition for submitted jobs.\nWe see that both partitions are in an UP state.\nSome configurations may include partitions for larger jobs\nthat are DOWN except on weekends or at night. The information\nabout each partition may be split over more than one line so that\nnodes in different states can be identified.\nIn this case, the two nodes adev[1-2] are down.\nThe * following the state down indicate the nodes are\nnot responding. Note the use of a concise expression for node\nname specification with a common prefix adev and numeric\nranges or specific numbers identified. This format allows for\nvery large clusters to be easily managed.\nThe sinfo command\nhas many options to easily let you view the information of interest\nto you in whatever format you prefer.\nSee the man page for more information.\nadev0: sinfo\nPARTITION AVAIL  TIMELIMIT NODES  STATE NODELIST\ndebug*       up      30:00     2  down* adev[1-2]\ndebug*       up      30:00     3   idle adev[3-5]\nbatch        up      30:00     3  down* adev[6,13,15]\nbatch        up      30:00     3  alloc adev[7-8,14]\nbatch        up      30:00     4   idle adev[9-12]\nNext we determine what jobs exist on the system using the\nsqueue command. The\nST field is job state.\nTwo jobs are in a running state (R is an abbreviation\nfor Running) while one job is in a pending state\n(PD is an abbreviation for Pending).\nThe TIME field shows how long the jobs have run\nfor using the format days-hours:minutes:seconds.\nThe NODELIST(REASON) field indicates where the\njob is running or the reason it is still pending. Typical\nreasons for pending jobs are Resources (waiting\nfor resources to become available) and Priority\n(queued behind a higher priority job).\nThe squeue command\nhas many options to easily let you view the information of interest\nto you in whatever format you prefer.\nSee the man page for more information.\nadev0: squeue\nJOBID PARTITION  NAME  USER ST  TIME NODES NODELIST(REASON)\n65646     batch  chem  mike  R 24:19     2 adev[7-8]\n65647     batch   bio  joan  R  0:09     1 adev14\n65648     batch  math  phil PD  0:00     6 (Resources)\nThe scontrol command\ncan be used to report more detailed information about\nnodes, partitions, jobs, job steps, and configuration.\nIt can also be used by system administrators to make\nconfiguration changes. A couple of examples are shown\nbelow. See the man page for more information.\nadev0: scontrol show partition\nPartitionName=debug TotalNodes=5 TotalCPUs=40 RootOnly=NO\n   Default=YES OverSubscribe=FORCE:4 PriorityTier=1 State=UP\n   MaxTime=00:30:00 Hidden=NO\n   MinNodes=1 MaxNodes=26 DisableRootJobs=NO AllowGroups=ALL\n   Nodes=adev[1-5] NodeIndices=0-4\n\nPartitionName=batch TotalNodes=10 TotalCPUs=80 RootOnly=NO\n   Default=NO OverSubscribe=FORCE:4 PriorityTier=1 State=UP\n   MaxTime=16:00:00 Hidden=NO\n   MinNodes=1 MaxNodes=26 DisableRootJobs=NO AllowGroups=ALL\n   Nodes=adev[6-15] NodeIndices=5-14\n\n\nadev0: scontrol show node adev1\nNodeName=adev1 State=DOWN* CPUs=8 AllocCPUs=0\n   RealMemory=4000 TmpDisk=0\n   Sockets=2 Cores=4 Threads=1 Weight=1 Features=intel\n   Reason=Not responding [slurm@06/02-14:01:24]\n\n65648     batch  math  phil PD  0:00     6 (Resources)\nadev0: scontrol show job\nJobId=65672 UserId=phil(5136) GroupId=phil(5136)\n   Name=math\n   Priority=4294901603 Partition=batch BatchFlag=1\n   AllocNode:Sid=adev0:16726 TimeLimit=00:10:00 ExitCode=0:0\n   StartTime=06/02-15:27:11 EndTime=06/02-15:37:11\n   JobState=PENDING NodeList=(null) NodeListIndices=\n   NumCPUs=24 ReqNodes=1 ReqS:C:T=1-65535:1-65535:1-65535\n   OverSubscribe=1 Contiguous=0 CPUs/task=0 Licenses=(null)\n   MinCPUs=1 MinSockets=1 MinCores=1 MinThreads=1\n   MinMemory=0 MinTmpDisk=0 Features=(null)\n   Dependency=(null) Account=(null) Requeue=1\n   Reason=None Network=(null)\n   ReqNodeList=(null) ReqNodeListIndices=\n   ExcNodeList=(null) ExcNodeListIndices=\n   SubmitTime=06/02-15:27:11 SuspendTime=None PreSusTime=0\n   Command=/home/phil/math\n   WorkDir=/home/phil\nIt is possible to create a resource allocation and launch\nthe tasks for a job step in a single command line using the\nsrun command. Depending\nupon the MPI implementation used, MPI jobs may also be\nlaunched in this manner.\nSee the MPI section for more MPI-specific information.\nIn this example we execute /bin/hostname\non three nodes (-N3) and include task numbers on the output (-l).\nThe default partition will be used.\nOne task per node will be used by default.\nNote that the srun command has\nmany options available to control what resource are allocated\nand how tasks are distributed across those resources.\nadev0: srun -N3 -l /bin/hostname\n0: adev3\n1: adev4\n2: adev5\nThis variation on the previous example executes\n/bin/hostname in four tasks (-n4).\nOne processor per task will be used by default (note that we don't specify\na node count).\nadev0: srun -n4 -l /bin/hostname\n0: adev3\n1: adev3\n2: adev3\n3: adev3\nOne common mode of operation is to submit a script for later execution.\nIn this example the script name is my.script and we explicitly use\nthe nodes adev9 and adev10 (-w \"adev[9-10]\", note the use of a\nnode range expression).\nWe also explicitly state that the subsequent job steps will spawn four tasks\neach, which will ensure that our allocation contains at least four processors\n(one processor per task to be launched).\nThe output will appear in the file my.stdout (\"-o my.stdout\").\nThis script contains a timelimit for the job embedded within itself.\nOther options can be supplied as desired by using a prefix of \"#SBATCH\" followed\nby the option at the beginning of the script (before any commands to be executed\nin the script).\nOptions supplied on the command line would override any options specified within\nthe script.\nNote that my.script contains the command /bin/hostname\nthat executed on the first node in the allocation (where the script runs) plus\ntwo job steps initiated using the srun command\nand executed sequentially.\nadev0: cat my.script\n#!/bin/sh\n#SBATCH --time=1\n/bin/hostname\nsrun -l /bin/hostname\nsrun -l /bin/pwd\n\nadev0: sbatch -n4 -w \"adev[9-10]\" -o my.stdout my.script\nsbatch: Submitted batch job 469\n\nadev0: cat my.stdout\nadev9\n0: adev9\n1: adev9\n2: adev10\n3: adev10\n0: /home/jette\n1: /home/jette\n2: /home/jette\n3: /home/jette\nThe final mode of operation is to create a resource allocation\nand spawn job steps within that allocation.\nThe salloc command is used\nto create a resource allocation and typically start a shell within\nthat allocation.\nOne or more job steps would typically be executed within that allocation\nusing the srun command to launch the tasks\n(depending upon the type of MPI being used, the launch mechanism may\ndiffer, see MPI details below).\nFinally the shell created by salloc would\nbe terminated using the exit command.\nSlurm does not automatically migrate executable or data files\nto the nodes allocated to a job.\nEither the files must exists on local disk or in some global file system\n(e.g. NFS or Lustre).\nWe provide the tool sbcast to transfer\nfiles to local storage on allocated nodes using Slurm's hierarchical\ncommunications.\nIn this example we use sbcast to transfer\nthe executable program a.out to /tmp/joe.a.out on local storage\nof the allocated nodes.\nAfter executing the program, we delete it from local storage\ntux0: salloc -N1024 bash\n$ sbcast a.out /tmp/joe.a.out\nGranted job allocation 471\n$ srun /tmp/joe.a.out\nResult is 3.14159\n$ srun rm /tmp/joe.a.out\n$ exit\nsalloc: Relinquishing job allocation 471\nIn this example, we submit a batch job, get its status, and cancel it. \nadev0: sbatch test\nsrun: jobid 473 submitted\n\nadev0: squeue\nJOBID PARTITION NAME USER ST TIME  NODES NODELIST(REASON)\n  473 batch     test jill R  00:00 1     adev9\n\nadev0: scancel 473\n\nadev0: squeue\nJOBID PARTITION NAME USER ST TIME  NODES NODELIST(REASON)\nBest Practices, Large Job Counts\n\nConsider putting related work into a single Slurm job with multiple job\nsteps both for performance reasons and ease of management.\nEach Slurm job can contain a multitude of job steps and the overhead in\nSlurm for managing job steps is much lower than that of individual jobs.Job arrays are an efficient mechanism of\nmanaging a collection of batch jobs with identical resource requirements.\nMost Slurm commands can manage job arrays either as individual elements (tasks)\nor as a single entity (e.g. delete an entire job array in a single command).MPIMPI use depends upon the type of MPI being used.\nThere are three fundamentally different modes of operation used\nby these various MPI implementations.\n\nSlurm directly launches the tasks and performs initialization of\ncommunications through the PMI2 or PMIx APIs. (Supported by most\nmodern MPI implementations.)\nSlurm creates a resource allocation for the job and then\nmpirun launches tasks using Slurm's infrastructure (older versions of\nOpenMPI).\nSlurm creates a resource allocation for the job and then\nmpirun launches tasks using some mechanism other than Slurm,\nsuch as SSH or RSH.\nThese tasks are initiated outside of Slurm's monitoring\nor control. Slurm's epilog should be configured to purge\nthese tasks when the job's allocation is relinquished. The\nuse of pam_slurm_adopt is also strongly recommended.\n\nLinks to instructions for using several varieties of MPI\nwith Slurm are provided below.\n\nIntel MPI\nMPICH2\nMVAPICH2\nOpen MPI\n\nLast modified 29 June 2021\n"
        },
        {
            "title": "Navigation",
            "content": "\nSlurm Workload Manager\nVersion 24.05\n\n\nAbout\n\nOverview\nRelease Notes\n\n\n\nUsing\n\nDocumentation\nFAQ\nPublications\n\n\n\nInstalling\n\nDownload\nRelated Software\nInstallation Guide\n\n\n\nGetting Help\n\nMailing Lists\nSupport and Training\nTroubleshooting\n\n\n"
        }
    ]
}