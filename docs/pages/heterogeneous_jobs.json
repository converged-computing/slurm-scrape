{
    "url": "https://slurm.schedmd.com/heterogeneous_jobs.html",
    "sections": [
        {
            "title": "\n\nSlurm Workload Manager\n\n",
            "content": "\n\nSchedMD\n\n"
        },
        {
            "title": "Heterogeneous Job Support",
            "content": "\nOverview\nSubmitting Jobs\nBurst Buffers\n\nManaging Jobs\nAccounting\n\nLaunching Applications (Job Steps)\nEnvironment Variables\nExamples\nLimitations\nHeterogeneous Steps\nSystem Administrator Information\nOverviewSlurm version 17.11 and later supports the ability to submit and manage\nheterogeneous jobs, in which each component has virtually all job options\navailable including partition, account and QOS (Quality Of Service).\nFor example, part of a job might require four cores and 4 GB for each of 128\ntasks while another part of the job would require 16 GB of memory and one CPU.Submitting Jobs\n\nThe salloc, sbatch and srun commands can all be used\nto submit heterogeneous jobs.\nResource specifications for each component of the heterogeneous job should be\nseparated with \":\" character.\nFor example:\n$ sbatch --cpus-per-task=4 --mem-per-cpu=1  --ntasks=128 : \\\n         --cpus-per-task=1 --mem-per-cpu=16 --ntasks=1 my.bash\nOptions specified for one component of a heterogeneous job (or job step) will\nbe used for subsequent components to the extent which is expected to be helpful.\nPropagated options can be reset as desired for each component (e.g. a different\naccount name could be specified for each hetjob component.\nFor example, --immediate and --job-name are propagated, while\n--ntasks and --mem-per-cpu are reset to default values for each\ncomponent.\nA list of propagated options follows.\n--account\n--acctg-freq\n--begin\n--cluster-constraint\n--clusters\n--comment\n--deadline\n--delay-boot\n--dependency\n--distribution\n--epilog            (option available only in srun)\n--error\n--export\n--export-file\n--exclude\n--get-user-env\n--gid\n--hold\n--ignore-pbs\n--immediate\n--input\n--job-name\n--kill-on-bad-exit  (option available only in srun)\n--label             (option available only in srun)\n--mcs-label\n--mem\n--msg-timeout       (option available only in srun)\n--no-allocate       (option available only in srun)\n--no-requeue\n--nice\n--no-kill\n--open-mode         (option available only in srun)\n--output\n--parsable\n--priority\n--profile\n--propagate\n--prolog            (option available only in srun)\n--pty               (option available only in srun)\n--qos\n--quiet\n--quit-on-interrupt (option available only in srun)\n--reboot\n--reservation\n--requeue\n--signal\n--slurmd-debug      (option available only in srun)\n--task-epilog       (option available only in srun)\n--task-prolog       (option available only in srun)\n--time\n--test-only\n--time-min\n--uid\n--unbuffered        (option available only in srun)\n--verbose\n--wait\n--wait-all-nodes\n--wckey\n--workdir\nThe task distribution specification applies separately within each job\ncomponent. Consider for example a heterogeneous job with each component being\nallocated 4 CPUs on 2 nodes. In our example, job component zero is allocated\n2 CPUs on node \"nid00001\" and 2 CPUs on node \"nid00002\". Job component one is\nallocated 2 CPUs on node \"nid00003\" and 2 CPUs on node \"nid00004\". A task\ndistribution of \"cyclic\" will distribute the first 4 tasks in a cyclic fashion\non nodes \"nid00001\" and \"nid00002\", then distribute the next 4 tasks in a cyclic\nfashion on nodes \"nid00003\" and \"nid00004\" as shown below.\nNode nid00001Node nid00002Node nid00003Node nid00004\nRank 0Rank 1Rank 4Rank 5\nRank 2Rank 3Rank 6Rank 7\nSome options should be specified only in the first hetjob component.\nFor example, specifying a batch job output file in the second hetjob component's\noptions will result in the first hetjob component (where the batch script\nexecutes) using the default output file name.Environment variables used to specify default options for the job submit\ncommand will be applied to every component of the heterogeneous job\n(e.g. SBATCH_ACCOUNT).Batch job options can be included in the submitted script for multiple\nheterogeneous job components. Each component should be separated by a line\ncontaining the line \"#SBATCH hetjob\" as shown below.\n$ cat new.bash\n#!/bin/bash\n#SBATCH --cpus-per-task=4 --mem-per-cpu=16g --ntasks=1\n#SBATCH hetjob\n#SBATCH --cpus-per-task=2 --mem-per-cpu=1g  --ntasks=8\n\nsrun run.app\n\n$ sbatch new.bash\nIs equivalent to the following:\n$ cat my.bash\n#!/bin/bash\nsrun run.app\n\n$ sbatch --cpus-per-task=4 --mem-per-cpu=16g --ntasks=1 : \\\n         --cpus-per-task=2 --mem-per-cpu=1g  --ntasks=8 my.bash\nThe batch script will be executed in the first node in the first component\nof the heterogeneous job. For the above example, that will be the job component\nwith 1 task, 4 CPUs and 64 GB of memory (16 GB for each of the 4 CPUs).If a heterogeneous job is submitted to run in multiple clusters not\npart of a federation (e.g. \"sbatch --cluster=alpha,beta ...\") then the entire\njob will be sent to the cluster expected to be able to start all components\nat the earliest time.A resource limit test is performed when a heterogeneous job is submitted in\norder to immediately reject jobs that will not be able to start with current\nlimits.\nThe individual components of the heterogeneous job are validated, like all\nregular jobs.\nThe heterogeneous job as a whole is also tested, but in a more limited\nfashion with respect to quality of service (QOS) limits.\nEach component of a heterogeneous job counts as a \"job\" with respect to\nresource limits.Burst Buffers\n\nA burst buffer can either be persistent or linked to a specific job ID.\nSince a heterogeneous job consists of multiple job IDs, a job-specific burst\nbuffer will be associated with only one heterogeneous job component.\nEach component can have its own burst buffer directives, and they are processed\nseparately. Only a persistent burst buffer can be accessed by all components\nof a heterogeneous job. Persistent burst buffers are only available in the\ndatawarp plugin. A sample batch script demonstrating this for the datawarp\nplugin is appended.\n#!/bin/bash\n#SBATCH --nodes=1 --constraint=haswell\n#BB create_persistent name=alpha capacity=10 access=striped type=scratch\n#DW persistentdw name=alpha\n#SBATCH hetjob\n#SBATCH --nodes=16 --constraint=knl\n#DW persistentdw name=alpha\n...\nNOTE: Cray's DataWarp interface directly reads the job script, but\nhas no knowledge of \"Slurm's \"hetjob\" directive, so Slurm internally rebuilds\nthe script for each job component so that only that job component's burst buffer\ndirectives are included in that script. The batch script's first component of the\njob will be modified in order to replace the burst buffer directives of other\njob components with \"#EXCLUDED directive\" where directive is \"DW\" or \"BB\"\nfor the datawarp plugin and is the\nconfigured value for the lua plugin.\nThis prevents their interpretation by Cray infrastructure and aids\nadministrators in writing an interface for the lua plugin.\nSince the batch script will only be executed by the first job\ncomponent, the subsequent job components will not include commands from the\noriginal script. These scripts are built and managed by Slurm for internal\npurposes (and visible from various Slurm commands) from a user script as shown\nabove. An example is shown below:\nRebuilt script for first job component\n\n#!/bin/bash\n#SBATCH --nodes=1 --constraint=haswell\n#BB create_persistent name=alpha capacity=10 access=striped type=scratch\n#DW persistentdw name=alpha\n#SBATCH hetjob\n#SBATCH --nodes=16 --constraint=knl\n#EXCLUDED DW persistentdw name=alpha\n...\n\n\nRebuilt script for second job component\n\n#!/bin/bash\n#SBATCH --nodes=16 --constraint=knl\n#DW persistentdw name=alpha\nexit 0\nManaging JobsInformation maintained in Slurm for a heterogeneous job includes:\njob_id: Each component of a heterogeneous job will have its own\nunique job_id.\nhet_job_id: This identification number applies to all components\nof the heterogeneous job. All components of the same job will have the same\nhet_job_id value and it will be equal to the job_id of the\nfirst component. We refer to this as the \"heterogeneous job leader\".\nhet_job_id_set: Regular expression identifying all job_id\nvalues associated with the job.\nhet_job_offset: A unique sequence number applied to each component\nof the heterogeneous job. The first component will have a het_job_offset\nvalue of 0, the next a value of 1, etc.\n\n\njob_id\nhet_job_id\nhet_job_offset\nhet_job_id_set\n\n1231230123-127\n1241231123-127\n1251232123-127\n1261233123-127\n1271234123-127\nTable 1: Example job IDsThe squeue and sview commands report the\ncomponents of a heterogeneous job using the format\n\"<het_job_id>+<het_job_offset>\".\nFor example \"123+4\" would represent heterogeneous job id 123 and its fifth\ncomponent (note: the first component has a het_job_offset value of 0).A request for a specific job ID that identifies a ID of the first component\nof a heterogeneous job (i.e. the \"heterogeneous job leader\") will return\ninformation about all components of that job. For example:\n$ squeue --job=93\nJOBID PARTITION  NAME  USER ST  TIME  NODES NODELIST\n 93+0     debug  bash  adam  R 18:18      1 nid00001\n 93+1     debug  bash  adam  R 18:18      1 nid00011\n 93+2     debug  bash  adam  R 18:18      1 nid00021\nA request to cancel or otherwise signal a heterogeneous job leader will be applied to\nall components of that heterogeneous job. A request to cancel a specific component of\nthe heterogeneous job using the \"#+#\" notation will apply only to that specific component.\nFor example:\n$ squeue --job=93\nJOBID PARTITION  NAME  USER ST  TIME  NODES NODELIST\n 93+0     debug  bash  adam  R 19:18      1 nid00001\n 93+1     debug  bash  adam  R 19:18      1 nid00011\n 93+2     debug  bash  adam  R 19:18      1 nid00021\n$ scancel 93+1\n$ squeue --job=93\nJOBID PARTITION  NAME  USER ST  TIME  NODES NODELIST\n 93+0     debug  bash  adam  R 19:38      1 nid00001\n 93+2     debug  bash  adam  R 19:38      1 nid00021\n$ scancel 93\n$ squeue --job=93\nJOBID PARTITION  NAME  USER ST  TIME  NODES NODELIST\nWhile a heterogeneous job is in pending state, only the entire job can be\ncancelled rather than its individual components.\nA request to cancel an individual component of a heterogeneous job in\npending state will return an error.\nAfter the job has begun execution, the individual component can be cancelled.Email notification for job state changes (the --mail-type option)\nis only supported for a heterogeneous job leader. Requests for email\nnotifications for other components of a heterogeneous job will be silently\nignored.Requests to modify an individual component of a job using the scontrol\ncommand must specify the job ID with the \"#+#\" notation.\nA request to modify a job by specifying the het_job_id will modify all\ncomponents of a heterogeneous job.\nFor example:\n# Change the account of component 2 of heterogeneous job 123:\n$ scontrol update jobid=123+2 account=abc\n\n# Change the time limit of all components of heterogeneous job 123:\n$ scontrol update jobid=123 timelimit=60\nRequests to perform the following operations a job can only be requested for\na heterogeneous job leader and will be applied to all components of that\nheterogeneous job. Requests to operate on individual components of the\nheterogeneous will return an error.\nrequeue\nresume\nsuspend\nThe sbcast command supports heterogeneous job allocations. By default,\nsbcast will copy files to all nodes in the job allocation. The -j/--jobid\noption can be used to copy files to individual components as shown below.\n$ sbcast --jobid=123   data /tmp/data\n$ sbcast --jobid=123.0 app0 /tmp/app0\n$ sbcast --jobid=123.1 app1 /tmp/app1\nThe srun commands --bcast option will transfer files to the nodes associated\nwith the application to be launched as specified by the --het-group option.Slurm has a configuration option to control behavior of some commands with\nrespect to heterogeneous jobs.\nBy default a request to cancel, hold or release a job ID that is not the\nhet_job_id, but that of a job component will only operate that one component\nof the heterogeneous job.\nIf SchedulerParameters configuration parameter includes the option\n\"whole_hetjob\" then the operation would apply to all components of the job if\nany job component is specified to be operated upon. In the below example, the\nscancel command will either cancel all components of job 93 if\nSchedulerParameters=whole_hetjob is configured, otherwise only job 93+1 will be\ncancelled. If a specific heterogeneous job component is specified (e.g. \"scancel\n93+1\"), then only that one component will be effected.\n$ squeue --job=93\nJOBID PARTITION  NAME  USER ST  TIME  NODES NODELIST\n 93+0     debug  bash  adam  R 19:18      1 nid00001\n 93+1     debug  bash  adam  R 19:18      1 nid00011\n 93+2     debug  bash  adam  R 19:18      1 nid00021\n$ scancel 94 (where job ID 94 is equivalent to 93+1)\n# Cancel 93+0, 93+1 and 93+2 if SchedulerParameters includes \"whole_hetjob\"\n# Cancel only 93+1 if SchedulerParameters does not include \"whole_hetjob\"\nAccountingSlurm's accounting database records the het_job_id and het_job_offset\nfields.\nThe sacct command reports job's using the format\n\"<het_job_id>+<het_job_offset>\" and can accept a job ID\nspecification for filtering using the same format.\nIf a het_job_id value is specified as a job filter, then information about\nall components of that job will be reported as shown below by default.\nThe --whole-hetjob=[yes|no] option can be used to force to report\nthe information about all the components of that job or just about the specific\ncomponent requested, no matter if the job filter includes the het_job_id\n(leader) or not.\n\n$ sacct -j 67767\n  JobID JobName Partition Account AllocCPUS     State ExitCode \n------- ------- --------- ------- --------- --------- -------- \n67767+0     foo     debug    test         2 COMPLETED      0:0 \n67767+1     foo     debug    test         4 COMPLETED      0:0 \n\n$  sacct -j 67767+1\n  JobID JobName Partition Account AllocCPUS     State ExitCode \n------- ------- --------- ------- --------- --------- -------- \n67767+1     foo     debug    test         4 COMPLETED      0:0 \n\n$  sacct -j 67767 --whole-hetjob=no\n  JobID JobName Partition Account AllocCPUS     State ExitCode\n------- ------- --------- ------- --------- --------- --------\n67767+0     foo     debug    test         4 COMPLETED      0:0\n\n$ sacct -j 67767+1 --whole-hetjob=yes\n  JobID JobName Partition Account AllocCPUS     State ExitCode\n------- ------- --------- ------- --------- --------- --------\n67767+0     foo     debug    test         2 COMPLETED      0:0\n67767+1     foo     debug    test         4 COMPLETED      0:0\nLaunching Applications (Job Steps)\n\nThe srun command is used to launch applications.\nBy default, the application is launched only on the first component of a\nheterogeneous job, but options are available to support different behaviors.srun's \"--het-group\" option defines which hetjob component(s) are to have\napplications launched for them. The --het-group option takes an expression\ndefining which component(s) are to launch an application for an individual\nexecution of the srun command. The expression can contain one or more component\nindex values in a comma separated list. Ranges of index values can be specified\nin a hyphen separated list. By default, an application is launched only on\ncomponent number zero. Some examples follow:\n--het-group=2\n--het-group=0,4\n--het-group=1,3-5\nIMPORTANT: The ability to execute a single application across more\nthan one job allocation does not work with all MPI implementations or Slurm MPI\nplugins. Slurm's ability to execute such an application can be disabled on the\nentire cluster by adding \"disable_hetjob_steps\" to Slurm's SchedulerParameters\nconfiguration parameter.IMPORTANT: While the srun command can be used to launch heterogeneous\njob steps, mpirun would require substantial modification to support\nheterogeneous applications. We are aware of no such mpirun development efforts\nat this time.By default, the applications launched by a single execution of the srun\ncommand (even for different components of the heterogeneous job) are combined\ninto one MPI_COMM_WORLD with non-overlapping task IDs.As with the salloc and sbatch commands, the \":\" character is used to\nseparate multiple components of a heterogeneous job.\nThis convention means that the stand-alone \":\" character can not be used as an\nargument to an application launched by srun.\nThis includes the ability to execute different applications and arguments\nfor each job component.\nIf some heterogeneous job component lacks an application specification, the next\napplication specification provided will be used for earlier components lacking\none as shown below.\n$ srun --label -n2 : -n1 hostname\n0: nid00012\n1: nid00012\n2: nid00013\nIf multiple srun commands are executed concurrently, this may result in resource\ncontention (e.g. memory limits preventing some job steps components from being\nallocated resources because of two srun commands executing at the same time).\nIf the srun --het-group option is used to create multiple job steps (for the\ndifferent components of a heterogeneous job), those job steps will be created\nsequentially.\nWhen multiple srun commands execute at the same time, this may result in some\nstep allocations taking place, while others are delayed.\nOnly after all job step allocations have been granted will the application\nbeing launched.All components of a job step will have the same step ID value.\nIf job steps are launched on subsets of the job components there may be gaps in\nthe step ID values for individual job components.\n$ salloc -n1 : -n2 beta bash\nsalloc: Pending job allocation 1721\nsalloc: Granted job allocation 1721\n$ srun --het-group=0,1 true   # Launches steps 1721.0 and 1722.0\n$ srun --het-group=0   true   # Launches step  1721.1, no 1722.1\n$ srun --het-group=0,1 true   # Launches steps 1721.2 and 1722.2\nThe maximum het-group specified in a job step allocation (either explicitly\nspecified or implied by the \":\" separator) must not exceed the number of\ncomponents in the heterogeneous job allocation. For example\n$ salloc -n1 -C alpha : -n2 -C beta bash\nsalloc: Pending job allocation 1728\nsalloc: Granted job allocation 1728\n$ srun --het-group=0,1 hostname\nnid00001\nnid00008\nnid00008\n$ srun hostname : date : id\nerror: Attempt to run a job step with het-group value of 2,\n       but the job allocation has maximum value of 1\nEnvironment Variables\n\nSlurm environment variables will be set independently for each component of\nthe job by appending \"_HET_GROUP_\" and a sequence number to the usual name.\nIn addition, the \"SLURM_JOB_ID\" environment variable will contain the job ID\nof the heterogeneous job leader and \"SLURM_HET_SIZE\" will contain the number of\ncomponents in the job. Note that if using srun with a single specific\nhet group (for instance --het-group=1) \"SLURM_JOB_ID\" will contain the job\nID of the heterogeneous job leader. The job ID for a specific heterogeneous\ncomponent is set in \"SLURM_JOB_ID_HET_GROUP_<component_id>\". For example:\n\n$ salloc -N1 : -N2 bash\nsalloc: Pending job allocation 11741\nsalloc: job 11741 queued and waiting for resources\nsalloc: job 11741 has been allocated resources\n$ env | grep SLURM\nSLURM_JOB_ID=11741\nSLURM_HET_SIZE=2\nSLURM_JOB_ID_HET_GROUP_0=11741\nSLURM_JOB_ID_HET_GROUP_1=11742\nSLURM_JOB_NODES_HET_GROUP_0=1\nSLURM_JOB_NODES_HET_GROUP_1=2\nSLURM_JOB_NODELIST_HET_GROUP_0=nid00001\nSLURM_JOB_NODELIST_HET_GROUP_1=nid[00011-00012]\n...\n$ srun --het-group=1 printenv SLURM_JOB_ID\n11741\n11741\n$ srun --het-group=0 printenv SLURM_JOB_ID\n11741\n$ srun --het-group=1 printenv SLURM_JOB_ID_HET_GROUP_1\n11742\n11742\n$ srun --het-group=0 printenv SLURM_JOB_ID_HET_GROUP_0\n11741\nThe various MPI implementations rely heavily upon Slurm environment variables\nfor proper operation.\nA single MPI application executing in a single MPI_COMM_WORLD requires a\nuniform set of environment variables that reflect a single job allocation.\nThe example below shows how Slurm sets environment variables for MPI.\n$ salloc -N1 : -N2 bash\nsalloc: Pending job allocation 11741\nsalloc: job 11751 queued and waiting for resources\nsalloc: job 11751 has been allocated resources\n$ env | grep SLURM\nSLURM_JOB_ID=11751\nSLURM_HET_SIZE=2\nSLURM_JOB_ID_HET_GROUP_0=11751\nSLURM_JOB_ID_HET_GROUP_1=11752\nSLURM_JOB_NODELIST_HET_GROUP_0=nid00001\nSLURM_JOB_NODELIST_HET_GROUP_1=nid[00011-00012]\n...\n$ srun --het-group=0,1 env | grep SLURM\nSLURM_JOB_ID=11751\nSLURM_JOB_NODELIST=nid[00001,00011-00012]\n...\nExamplesCreate a heterogeneous resource allocation containing one node with 256GB\nof memory and a feature of \"haswell\" plus 2176 cores on 32 nodes with a\nfeature of \"knl\". Then launch a program called \"server\" on the \"haswell\" node\nand \"client\" on the \"knl\" nodes. Each application will be in its own\nMPI_COMM_WORLD.\nsalloc -N1 --mem=256GB -C haswell : \\\n       -n2176 -N32 --ntasks-per-core=1 -C knl bash\nsrun server &\nsrun --het-group=1 client &\nwait\nThis variation of the above example launches programs \"server\" and \"client\"\nin a single MPI_COMM_WORLD.\nsalloc -N1 --mem=256GB -C haswell : \\\n       -n2176 -N32 --ntasks-per-core=1 -C knl bash\nsrun server : client\nThe SLURM_PROCID environment variable will be set to reflect a global\ntask rank. Each spawned process will have a unique SLURM_PROCID.Similarly, the SLURM_NPROCS and SLURM_NTASKS environment variables will be set\nto reflect a global task count (both environment variables will have the same\nvalue).\nSLURM_NTASKS will be set to the total count of tasks in all components.\nNote that the task rank and count values are needed by MPI and typically\ndetermined by examining Slurm environment variables.Limitations\n\nThe backfill scheduler has limitations in how it tracks usage of CPUs and\nmemory in the future.\nThis typically requires the backfill scheduler be able to allocate each\ncomponent of a heterogeneous job on a different node in order to begin its\nresource allocation, even if multiple components of the job do actually get\nallocated resources on the same node.In a federation of clusters, a heterogeneous job will execute entirely on\nthe cluster from which the job is submitted. The heterogeneous job will not\nbe eligible to migrate between clusters or to have different components of\nthe job execute on different clusters in the federation.Caution must be taken when submitting heterogeneous jobs that request\nmultiple overlapping partitions. When the partitions share the same resources\nit's possible to starve your own job by having the first job component request\nenough nodes that the scheduler isn't able to fill the subsequent request(s).\nConsider an example where you have partition p1 that contains 10 nodes\nand partition p2 that exists on 5 of the same nodes. If you submit a\nheterogeneous job that requests 5 nodes in p1 and 5 nodes in p2,\nthe scheduler may try to allocate some of the nodes from the p2\npartition for the first job component, preventing the scheduler from being\nable to fulfill the second request, resulting in a job that is never able to\nstart.Magnetic reservations cannot \"attract\" heterogeneous jobs - heterogeneous\njobs will only run in magnetic reservations if they explicitly request the\nreservation.Job arrays of heterogeneous jobs are not supported.The srun command's --no-allocate option is not supported\nfor heterogeneous jobs.Only one job step per heterogeneous job component can be launched by a\nsingle srun command (e.g.\n\"srun --het-group=0 alpha : --het-group=0 beta\" is not supported).The sattach command can only be used to attach to a single component of\na heterogeneous job at a time.License requests are only allowed on the first component\njob (e.g.\n\"sbatch -L ansys:2 : script.sh\").\nHeterogeneous jobs are only scheduled by the backfill scheduler plugin.\nThe more frequently executed scheduling logic only starts jobs on a first-in\nfirst-out (FIFO) basis and lacks logic for concurrently scheduling all\ncomponents of a heterogeneous job.\nHeterogeneous jobs are not supported on GANG scheduling operations.\nSlurm's Perl APIs do not support heterogeneous jobs.\nThe srun --multi-prog option can not be used to span more than one\nheterogeneous job component.\nThe srun --open-mode option is by default set to \"append\".\nAncient versions of OpenMPI and their derivatives (i.e. Cray MPI) are\ndependent upon communication ports being assigned to them by Slurm. Such MPI\njobs will experience step launch failure if any component of a\nheterogeneous job step is unable to acquire the allocated ports.\nNon-heterogeneous job steps will retry step launch using a new set of\ncommunication ports (no change in Slurm behavior).\n\nHeterogeneous Steps\n\n\nSlurm version 20.11 introduces the ability to request heterogeneous job\nsteps from within a non-homogeneous job allocation. This allows you the\nflexibility to have different layouts for job steps without requiring the\nuse of heterogeneous jobs, where having separate jobs for the components\nmay be undesirable.\nSome limitations for heterogeneous steps are that the steps must be able\nto run on unique nodes. You also cannot request heterogeneous steps from within\na heterogeneous job.\nAn example scenario would be if you have a task that needs to use 1 GPU\nper processor while another task needs all the available GPUs on a node with\nonly one processor. This can be accomplished like this:\n\n\n$ salloc -N2 --exclusive --gpus=10\nsalloc: Granted job allocation 61034\n$ srun -N1 -n4 --gpus=4 printenv SLURMD_NODENAME : -N1 -n1 --gpus=6 printenv SLURMD_NODENAME\nnode02\nnode01\nnode01\nnode01\nnode01\n\nSystem Administrator Information\n\n\nThe job submit plugin is invoked independently for each component of a\nheterogeneous job.\nThe spank_init_post_opt() function is invoked once for each component of a\nheterogeneous job. This permits site defined options on a per job component\nbasis.\nScheduling of heterogeneous jobs is performed only by the sched/backfill\nplugin and all heterogeneous job components are either all scheduled at the same\ntime or deferred. The pending reason of heterogeneous jobs isn't set until\nbackfill evaluation.\nIn order to ensure the timely initiation of both heterogeneous and\nnon-heterogeneous jobs, the backfill scheduler alternates between two different\nmodes on each iteration.\nIn the first mode, if a heterogeneous job component can not be initiated\nimmediately, its expected start time is recorded and all subsequent components\nof that job will be considered for starting no earlier than the latest\ncomponent's expected start time.\nIn the second mode, all heterogeneous job components will be considered for\nstarting no earlier than the latest component's expected start time.\nAfter completion of the second mode, all heterogeneous job expected start time\ndata is cleared and the first mode will be used in the next backfill scheduler\niteration.\nRegular (non-heterogeneous jobs) are scheduled independently on each iteration\nof the backfill scheduler.\n For example, consider a heterogeneous job with three components.\nWhen considered as independent jobs, the components could be initiated at times\nnow (component 0), now plus 2 hour (component 1), and now plus 1 hours\n(component 2).\nWhen the backfill scheduler runs in the first mode:\n\nComponent 0 will be noted to possible to start now, but not initiated due\nto the additional components to be initiated\nComponent 1 will be noted to be possible to start in 2 hours\nComponent 2 will not be considered for scheduling until 2 hours in the\nfuture, which leave some additional resources available for scheduling to other\njobs\n\nWhen the backfill scheduler executes next, it will use the second mode and\n(assuming no other state changes) all three job components will be considered\navailable for scheduling no earlier than 2 hours in the future, which may allow\nother jobs to be allocated resources before heterogeneous job component 0\ncould be initiated.\nThe heterogeneous job start time data will be cleared before the first\nmode is used in the next iteration in order to consider system status changes\nwhich might permit the heterogeneous to be initiated at an earlier time than\npreviously determined.\nA resource limit test is performed when a heterogeneous job is submitted in\norder to immediately reject jobs that will not be able to start with current\nlimits.\nThe individual components of the heterogeneous job are validated, like all\nregular jobs.\nThe heterogeneous job as a whole is also tested, but in a more limited\nfashion with respect to quality of service (QOS) limits.\nThis is due to the complexity of each job component having up to three sets of\nlimits (association, job QOS and partition QOS).\nNote that successful submission of any job (heterogeneous or otherwise) does\nnot ensure the job will be able to start without exceeding some limit.\nFor example a job's CPU limit test does not consider that CPUs might not be\nallocated individually, but resource allocations might be performed by whole\ncore, socket or node.\nEach component of a heterogeneous job counts as a \"job\" with respect to\nresource limits.\nFor example, a user might have a limit of 2 concurrent running jobs and submit\na heterogeneous job with 3 components.\nSuch a situation will have an adverse effect upon scheduling other jobs,\nespecially other heterogeneous jobs.\nLast modified 04 January 2024\n"
        },
        {
            "title": "Navigation",
            "content": "\nSlurm Workload Manager\nVersion 24.05\n\n\nAbout\n\nOverview\nRelease Notes\n\n\n\nUsing\n\nDocumentation\nFAQ\nPublications\n\n\n\nInstalling\n\nDownload\nRelated Software\nInstallation Guide\n\n\n\nGetting Help\n\nMailing Lists\nSupport and Training\nTroubleshooting\n\n\n"
        },
        {
            "title": "Heterogeneous Steps\n\n",
            "content": "Slurm version 20.11 introduces the ability to request heterogeneous job\nsteps from within a non-homogeneous job allocation. This allows you the\nflexibility to have different layouts for job steps without requiring the\nuse of heterogeneous jobs, where having separate jobs for the components\nmay be undesirable.Some limitations for heterogeneous steps are that the steps must be able\nto run on unique nodes. You also cannot request heterogeneous steps from within\na heterogeneous job.An example scenario would be if you have a task that needs to use 1 GPU\nper processor while another task needs all the available GPUs on a node with\nonly one processor. This can be accomplished like this:\n\n\n$ salloc -N2 --exclusive --gpus=10\nsalloc: Granted job allocation 61034\n$ srun -N1 -n4 --gpus=4 printenv SLURMD_NODENAME : -N1 -n1 --gpus=6 printenv SLURMD_NODENAME\nnode02\nnode01\nnode01\nnode01\nnode01\n\nSystem Administrator Information\n\n\nThe job submit plugin is invoked independently for each component of a\nheterogeneous job.\nThe spank_init_post_opt() function is invoked once for each component of a\nheterogeneous job. This permits site defined options on a per job component\nbasis.\nScheduling of heterogeneous jobs is performed only by the sched/backfill\nplugin and all heterogeneous job components are either all scheduled at the same\ntime or deferred. The pending reason of heterogeneous jobs isn't set until\nbackfill evaluation.\nIn order to ensure the timely initiation of both heterogeneous and\nnon-heterogeneous jobs, the backfill scheduler alternates between two different\nmodes on each iteration.\nIn the first mode, if a heterogeneous job component can not be initiated\nimmediately, its expected start time is recorded and all subsequent components\nof that job will be considered for starting no earlier than the latest\ncomponent's expected start time.\nIn the second mode, all heterogeneous job components will be considered for\nstarting no earlier than the latest component's expected start time.\nAfter completion of the second mode, all heterogeneous job expected start time\ndata is cleared and the first mode will be used in the next backfill scheduler\niteration.\nRegular (non-heterogeneous jobs) are scheduled independently on each iteration\nof the backfill scheduler.\n For example, consider a heterogeneous job with three components.\nWhen considered as independent jobs, the components could be initiated at times\nnow (component 0), now plus 2 hour (component 1), and now plus 1 hours\n(component 2).\nWhen the backfill scheduler runs in the first mode:\n\nComponent 0 will be noted to possible to start now, but not initiated due\nto the additional components to be initiated\nComponent 1 will be noted to be possible to start in 2 hours\nComponent 2 will not be considered for scheduling until 2 hours in the\nfuture, which leave some additional resources available for scheduling to other\njobs\n\nWhen the backfill scheduler executes next, it will use the second mode and\n(assuming no other state changes) all three job components will be considered\navailable for scheduling no earlier than 2 hours in the future, which may allow\nother jobs to be allocated resources before heterogeneous job component 0\ncould be initiated.\nThe heterogeneous job start time data will be cleared before the first\nmode is used in the next iteration in order to consider system status changes\nwhich might permit the heterogeneous to be initiated at an earlier time than\npreviously determined.\nA resource limit test is performed when a heterogeneous job is submitted in\norder to immediately reject jobs that will not be able to start with current\nlimits.\nThe individual components of the heterogeneous job are validated, like all\nregular jobs.\nThe heterogeneous job as a whole is also tested, but in a more limited\nfashion with respect to quality of service (QOS) limits.\nThis is due to the complexity of each job component having up to three sets of\nlimits (association, job QOS and partition QOS).\nNote that successful submission of any job (heterogeneous or otherwise) does\nnot ensure the job will be able to start without exceeding some limit.\nFor example a job's CPU limit test does not consider that CPUs might not be\nallocated individually, but resource allocations might be performed by whole\ncore, socket or node.\nEach component of a heterogeneous job counts as a \"job\" with respect to\nresource limits.\nFor example, a user might have a limit of 2 concurrent running jobs and submit\na heterogeneous job with 3 components.\nSuch a situation will have an adverse effect upon scheduling other jobs,\nespecially other heterogeneous jobs.\nLast modified 04 January 2024\n"
        },
        {
            "title": "System Administrator Information\n\n",
            "content": "The job submit plugin is invoked independently for each component of a\nheterogeneous job.The spank_init_post_opt() function is invoked once for each component of a\nheterogeneous job. This permits site defined options on a per job component\nbasis.Scheduling of heterogeneous jobs is performed only by the sched/backfill\nplugin and all heterogeneous job components are either all scheduled at the same\ntime or deferred. The pending reason of heterogeneous jobs isn't set until\nbackfill evaluation.\nIn order to ensure the timely initiation of both heterogeneous and\nnon-heterogeneous jobs, the backfill scheduler alternates between two different\nmodes on each iteration.\nIn the first mode, if a heterogeneous job component can not be initiated\nimmediately, its expected start time is recorded and all subsequent components\nof that job will be considered for starting no earlier than the latest\ncomponent's expected start time.\nIn the second mode, all heterogeneous job components will be considered for\nstarting no earlier than the latest component's expected start time.\nAfter completion of the second mode, all heterogeneous job expected start time\ndata is cleared and the first mode will be used in the next backfill scheduler\niteration.\nRegular (non-heterogeneous jobs) are scheduled independently on each iteration\nof the backfill scheduler. For example, consider a heterogeneous job with three components.\nWhen considered as independent jobs, the components could be initiated at times\nnow (component 0), now plus 2 hour (component 1), and now plus 1 hours\n(component 2).\nWhen the backfill scheduler runs in the first mode:\nComponent 0 will be noted to possible to start now, but not initiated due\nto the additional components to be initiated\nComponent 1 will be noted to be possible to start in 2 hours\nComponent 2 will not be considered for scheduling until 2 hours in the\nfuture, which leave some additional resources available for scheduling to other\njobs\nWhen the backfill scheduler executes next, it will use the second mode and\n(assuming no other state changes) all three job components will be considered\navailable for scheduling no earlier than 2 hours in the future, which may allow\nother jobs to be allocated resources before heterogeneous job component 0\ncould be initiated.The heterogeneous job start time data will be cleared before the first\nmode is used in the next iteration in order to consider system status changes\nwhich might permit the heterogeneous to be initiated at an earlier time than\npreviously determined.A resource limit test is performed when a heterogeneous job is submitted in\norder to immediately reject jobs that will not be able to start with current\nlimits.\nThe individual components of the heterogeneous job are validated, like all\nregular jobs.\nThe heterogeneous job as a whole is also tested, but in a more limited\nfashion with respect to quality of service (QOS) limits.\nThis is due to the complexity of each job component having up to three sets of\nlimits (association, job QOS and partition QOS).\nNote that successful submission of any job (heterogeneous or otherwise) does\nnot ensure the job will be able to start without exceeding some limit.\nFor example a job's CPU limit test does not consider that CPUs might not be\nallocated individually, but resource allocations might be performed by whole\ncore, socket or node.\nEach component of a heterogeneous job counts as a \"job\" with respect to\nresource limits.For example, a user might have a limit of 2 concurrent running jobs and submit\na heterogeneous job with 3 components.\nSuch a situation will have an adverse effect upon scheduling other jobs,\nespecially other heterogeneous jobs.Last modified 04 January 2024"
        }
    ]
}