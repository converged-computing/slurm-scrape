{
    "url": "https://slurm.schedmd.com/burst_buffer.html",
    "sections": [
        {
            "title": "\n\nSlurm Workload Manager\n\n",
            "content": "\n\nSchedMD\n\n"
        },
        {
            "title": "Slurm Burst Buffer Guide",
            "content": "\nOverview\nConfiguration (for system administrators)\n\nCommon Configuration\nDatawarp\nLua\n\n\nLua Implementation (for system\nadministrators)\n\nHow does burst_buffer.lua run?\nWarnings\n\n\nBurst Buffer Resources\n\nDatawarp\nLua\n\n\nJob Submission Commands\n\nDatawarp\nLua\n\n\nPersistent Burst Buffer Creation and Deletion Directives\nHeterogeneous Job Support\nCommand-line Job Options\n\nDatawarp\nLua\n\n\nSymbol Replacement\nStatus Commands\nAdvanced Reservations\nJob Dependencies\nBurst Buffer States and Job States\nOverviewThis guide explains how to use Slurm burst buffer plugins. Where appropriate,\nit explains how these plugins work in order to give guidance about how to best\nuse these plugins.The Slurm burst buffer plugins call a script at different points during the\nlifetime of a job:\nAt job submission\nWhile the job is pending after an estimated start time is\nestablished. This is called \"stage-in.\"\nOnce the job has been scheduled but has not started running yet.\nThis is called \"pre-run.\"\nOnce the job has completed or been cancelled, but Slurm has not\nreleased resources for the job yet. This is called \"stage-out.\"\nOnce the job has completed, and Slurm has released resources for\nthe job. This is called \"teardown.\"\nThis script runs on the slurmctld node. These are the supported plugins:\ndatawarp\nlua\nDatawarp\n\nThis plugin provides hooks to Cray's Datawarp APIs. Datawarp implements burst\nbuffers, which are a shared high-speed storage resource. Slurm provides support\nfor allocating these resources, staging files in, scheduling compute nodes for\njobs using these resources, and staging files out. Burst buffers can also be\nused as temporary storage during a job's lifetime, without file staging.\nAnother typical use case is for persistent storage, not associated with any\nspecific job.Lua\n\nThis plugin provides hooks to an API that is defined by a Lua script. This\nplugin was developed to provide system administrators with a way to do any task\n(not only file staging) at different points in a job's life cycle. These tasks\nmight include file staging, node maintenance, or any other task that is desired\nto run during one or more of the five job states listed above.The burst buffer APIs will only be called for a job that specifically\nrequests using them. The Job Submission Commands section\nexplains how a job can request using the burst buffer APIs.Configuration (for system administrators)\n\nCommon Configuration\n\n\nTo enable a burst buffer plugin, set BurstBufferType in\nslurm.conf. If it is not set, then no burst buffer plugin will be loaded.\nOnly one burst buffer plugin may be specified.\nIn slurm.conf, you may set DebugFlags=BurstBuffer for detailed\nlogging from the burst buffer plugin. This will result in very verbose logging\nand is not intended for prolonged use in a production system, but this may be\nuseful for debugging.\nTRES limits for burst buffers can be\nconfigured by association or QOS in the same way that TRES limits can be\nconfigured for nodes, CPUs, or any GRES. To make Slurm track burst buffer\nresources, add bb/datawarp (for the datawarp plugin) or\nbb/lua (for the lua plugin) to AccountingStorageTres\nin slurm.conf.\nThe size of a job's burst buffer requirements can be used as a factor in\nsetting the job priority as described in the\nmultifactor priority document.\nThe Burst Buffer Resources section explains how\nthese resources are defined.\nBurst-buffer-specific configurations can be set in burst_buffer.conf.\nConfiguration settings include things like which users may use burst buffers,\ntimeouts, paths to burst buffer scripts, etc. See the\nburst_buffer.conf manual\nfor more information.\nThe JSON-C library must be installed in order to build Slurm's\nburst_buffer/datawarp and burst_buffer/lua plugins,\nwhich must parse JSON format data. See Slurm's\nJSON installation information for\ndetails.\nDatawarp\n\nslurm.conf:\nBurstBufferType=burst_buffer/datawarp\nThe datawarp plugin calls two scripts:\ndw_wlm_cli - the Slurm burst_buffer/datawarp plugin calls this\nscript to perform burst buffer functions. It should have been provided by Cray.\nThe location of this script is defined by GetSysState in burst_buffer.conf. A\ntemplate of this script is provided with Slurm:\nsrc/plugins/burst_buffer/datawarp/dw_wlm_cli\ndwstat - the Slurm burst_buffer/datawarp plugin calls this script to\nget status information. It should have been provided by Cray. The location of\nthis script is defined by GetSysStatus in burst_buffer.conf. A template of this\nscript is provided with Slurm:\nsrc/plugins/burst_buffer/datawarp/dwstat\nLuaslurm.conf:\nBurstBufferType=burst_buffer/lua\nThe lua plugin calls a single script which must be named burst_buffer.lua.\nThis script needs to exist in the same directory as slurm.conf. The following\nfunctions are required to exist, although they may do nothing but return\nsuccess:\nslurm_bb_job_process\nslurm_bb_pools\nslurm_bb_job_teardown\nslurm_bb_setup\nslurm_bb_data_in\nslurm_bb_test_data_in\nslurm_bb_real_size\nslurm_bb_paths\nslurm_bb_pre_run\nslurm_bb_post_run\nslurm_bb_data_out\nslurm_bb_test_data_out\nslurm_bb_get_status\nA template of burst_buffer.lua is provided with Slurm:\netc/burst_buffer.lua.exampleThis template documents many more details about the functions such as\nrequired parameters, when each function is called, return values for each\nfunction, and some simple examples.Lua Implementation\n\nThis purpose of this section is to provide additional information about the\nLua plugin to help system administrators who desire to implement the Lua API.\nThe most important points in this section are:\nSome functions in burst_buffer.lua must run quickly and cannot be killed;\nthe remaining functions are allowed to run for as long as needed and can be\nkilled.\nA maximum of 512 copies of burst_buffer.lua are allowed to run concurrently\nin order to avoid exceeding system limits.\nHow does burst_buffer.lua run?\n\nLua scripts may either be run by themselves in a separate process via the\nfork() and exec() system calls, or they may be called\nvia Lua's C API from within an existing process. One of the goals of the lua\nplugin was to avoid calling fork() from within slurmctld because\nit can severely harm performance of the slurmctld. The datawarp plugin calls\nfork() and exec() from slurmctld for every burst\nbuffer API call, and this has been shown to severely harm slurmctld\nperformance. Therefore, slurmctld calls burst_buffer.lua using Lua's C API\ninstead of using fork().Some functions in burst_buffer.lua are allowed to run for a long time, but\nthey may need to be killed if the job is cancelled, if slurmctld is restarted,\nor if they run for longer than the configured timeout in burst_buffer.conf.\nHowever, a call to a Lua script via Lua's C API cannot be killed from within\nthe same process; only killing the entire process that called the Lua\nscript can kill the Lua script.To address this situation, burst_buffer.lua is called in two different\nways:\nThe slurm_bb_job_process, slurm_bb_pools and\nslurm_bb_paths functions are called from slurmctld.\nBecause of the explanation above,\na script running one of these functions cannot be killed. Since these functions\nare called while slurmctld holds some mutexes, it will be extremely harmful to\nslurmctld performance and responsiveness if they are slow. Because it is faster\nto call these functions directly than to call fork() to create a\nnew process, this was deemed an acceptable tradeoff. As a result, these\nfunctions cannot be killed.\nThe remaining functions in burst_buffer.lua are able to run longer without\nadverse effects. These need to be able to be killed. These functions are called\nfrom a lightweight Slurm daemon called slurmscriptd. Whenever one of these\nfunctions needs to run, slurmctld tells slurmscriptd to run that function;\nslurmscriptd then calls fork() to create a new process, then calls\nthe appropriate function. This avoids calling fork() from\nslurmctld while still providing a way to kill running copies of burst_buffer.lua\nwhen needed. As a result, these functions can be killed, and they will be\nkilled if they run for longer than the appropriate timeout value as configured\nin burst_buffer.conf.\nThe way in which each function is called is also documented in the\nburst_buffer.lua.example file.Warnings\n\nDo not install a signal handler in burst_buffer.lua because\nit is called directly from slurmctld. If slurmctld receives a signal, it\ncould attempt to run the signal handler from burst_buffer.lua, even after a call\nto burst_buffer.lua is completed, which results in a crash.Burst Buffer Resources\n\nThe burst buffer API may define burst buffer resource \"pools\" from which a\njob may request a certain amount of pool space. If a pool does not have\nsufficient space to fulfill a job's request, that job will remain pending until\nthe pool does have enough space. Once the pool has enough space, Slurm may begin\nstage-in for the job. When stage-in begins, Slurm subtracts the job's requested\nspace from the pool's available space. When teardown completes, Slurm adds the\njob's requested space back into the pool's available space. The\nJob Submission Commands section explains how a job may\nrequest space from a pool. Pool space is a scalar quantity.Datawarp\n\n\nPools are defined by dw_wlm_cli, and represent bytes. This\nscript prints a JSON-formatted string defining the pools to stdout.\nIf a job does not request a pool, then the pool defined by\nDefaultPool in burst_buffer.conf will be used. If a job does\nnot request a pool and DefaultPool\nis not defined, then the job will be rejected.\nLua\n\n\nPools are optional in this plugin, and can represent anything.\nDefaultPool in burst_buffer.conf is not used in this\nplugin.\nPools are defined by burst_buffer.lua in the function\nslurm_bb_pools. If pools are not desired, then this function should\njust return slurm.SUCCESS. If pools are desired, then this function\nshould return two values: (1) slurm.SUCCESS, and (2) a\nJSON-formatted string defining the pools. An example is provided in\nburst_buffer.lua.example. The current valid fields in the JSON string are:\n\nid - a string defining the name of the pool\nquantity - a number defining the amount of space in the\n\tpool\ngranularity - a number defining the lowest resolution of\n\tspace that may be allocated from this pool. If a job does not request a\n\tnumber that is a multiple of granularity, then the job's request will\n\tbe rounded up to the nearest multiple of granularity. For example,\n\tif granularity equals 1000, then the smallest amount of space that may\n\tbe allocated from this pool for a single job is 1000. If a job requests\n\tless than 1000 units from this pool, then the job's request will be\n\trounded up to 1000.\n\nJob Submission Commands\n\nThe normal mode of operation is for batch jobs to specify burst buffer\nrequirements within the batch script. Commented batch script lines containing a\nspecific directive (depending on which plugin is being used) will inform Slurm\nthat it should run the burst buffer stages for that job. These lines will also\ndescribe the burst buffer requirements for the job.The salloc and srun commands can specify burst buffer requirements with the\n--bb and --bbf options. This is described in the\nCommand-line Job Options section.All burst buffer directives should be specified in comments at the top of\nthe batch script. They may be placed before, after, or interspersed with any\n#SBATCH directives. All burst buffer stages happen at specific\npoints in the job's life cycle, as described in the\nOverview section; they do not happen during the job's\nexecution. For example, all of the persistent burst buffer (used only by the\ndatawarp plugin) creations and deletions happen before the job's compute\nportion happens. In a similar fashion, you can't run stage-in at various points\nin the script execution; burst buffer stage-in is performed before the job\nbegins and stage-out is performed after the job completes.For both plugins, a job may request a certain amount of space (size or\ncapacity) from a burst buffer resource pool.\nA pool specification is simply a string that matches the name of the\npool. For example: pool=pool1\nA capacity specification is a number indicating the amount of space\nrequired from the pool. A capacity specification can include a suffix of\n\"N\" (nodes), \"K|KiB\", \"M|MiB\", \"G|GiB\", \"T|TiB\", \"P|PiB\" (for powers of 1024)\nand \"KB\", \"MB\", \"GB\", \"TB\", \"PB\" (for powers of 1000). NOTE: Usually\nSlurm interprets KB, MB, GB, TB, PB, units as powers of 1024, but for Burst\nBuffers size specifications Slurm supports both IEC/SI formats. This is because\nthe CRAY API supports both formats.\nAt job submission, Slurm performs basic directive validation and also runs a\nfunction in the burst buffer script. This function can perform validation of\nthe directives used in the job script. If Slurm determines options are invalid,\nor if the burst buffer script returns an error, the job will be rejected and an\nerror message will be returned directly to the user.Note that unrecognized options may be ignored in order to support backward\ncompatibility (i.e. a job submission would not fail in the case of an option\nrecognized by some versions of Slurm, but not recognized by other versions). If\nthe job is accepted, but later fails (e.g. some problem staging files), the job\nwill be held and its \"Reason\" field will be set to an error message provided by\nthe underlying infrastructure.Users may also request to be notified by email upon completion of burst\nbuffer stage out using the --mail-type=stage_out or\n--mail-type=all option. The subject line of the email will be of\nthis form:\nSLURM Job_id=12 Name=my_app Staged Out, StageOut time 00:05:07\nThe following plugin subsections give additional information that is\nspecific to each plugin and provide example job scripts. Command-line examples\nare given in the\nCommand-line Job Options section.Datawarp\n\nThe directive of #DW (for \"DataWarp\") is used for burst buffer\ndirectives when using the burst_buffer/datawarp plugin. Please\nreference Cray documentation for details about the DataWarp options. For\nDataWarp systems, the directive of #BB can be used to create or\ndelete persistent burst buffer storage.\n\nNOTE: The #BB directive is used since the\ncommand is interpreted by Slurm and not by the Cray Datawarp software. This is\ndiscussed more in the Persistent Burst Buffer\nsection.For job-specific burst buffers, it is required to specify a burst buffer\ncapacity. If the job does not specify capacity then the job will\nbe rejected. A job may also specify the pool from which it wants resources; if\nthe job does not specify a pool, then the pool specified by DefaultPool in\nburst_buffer.conf will be used (if configured).The following job script requests burst buffer resources from the default\npool and requests files to be staged in and staged out:\n#!/bin/bash\n#DW jobdw type=scratch capacity=1GB access_mode=striped,private pfs=/scratch\n#DW stage_in type=file source=/tmp/a destination=/ss/file1\n#DW stage_out type=file destination=/tmp/b source=/ss/file1\nsrun application.sh\nLua\n\nThe default directive for this plugin is #BB_LUA. The directive\nused by this plugin may be changed by setting the Directive option in\nburst_buffer.conf. Since the directive must always begin with a #\nsign (which starts a comment in a shell script) this option should specify only\nthe string following the # sign. For example, if burst_buffer.conf\ncontains the following:Directive=BB_EXAMPLEthen the burst buffer directive will be #BB_EXAMPLE.If the Directive option is not specified in burst_buffer.conf, then\nthe default directive for this plugin (#BB_LUA) will be used.Since this plugin was designed to be generic and flexible, this plugin only\nrequires the directive to be given. If the directive is given, Slurm will run\nall burst buffer stages for the job.Example of the minimum information required for all burst buffer stages to\nrun for the job:\n#!/bin/bash\n#BB_LUA\nsrun application.sh\nBecause burst buffer pools are optional for this plugin (see the Burst Buffer Resources section), a job is not required to\nspecify a pool or capacity. If pools are provided by the burst buffer API,\nthen a job may request a pool and capacity:\n#!/bin/bash\n#BB_LUA pool=pool1 capacity=1K\nsrun application.sh\nA job may choose whether or not to specify a pool. If a job does not specify\na pool, then the job is still allowed to run and the burst buffer stages will\nstill run for this job (as long as the burst buffer directive was given). If\nthe job specifies a pool but that pool is not found, then the job is\nrejected.The system administrator may validate burst buffer options in the\nslurm_bb_job_process function in burst_buffer.lua. This might\ninclude requiring a job to specify a pool or validating any additional options\nthat the system administrator decides to implement.Persistent Burst Buffer Creation and Deletion Directives\n\nThis section only applies to the datawarp plugin, since persistent burst\nbuffers are not used in any other burst buffer plugin.These options are used to create and delete persistent burst buffers:\n#BB create_persistent name=<name> capacity=<number>\n[access=<access>] [pool=<pool> [type=<type>]\n#BB destroy_persistent name=<name> [hurry]\nOptions for creating and deleting persistent burst buffers:\nname - The persistent burst buffer name may not start with a numeric\nvalue (numeric names are reserved for job-specific burst buffers).\ncapacity - Described in the\nJob Submission Commands section.\npool - Described in the\nJob Submission Commands section.\naccess - The access parameter identifies the buffer access mode.\nSupported access modes for the datawarp plugin include:\n\nstriped\nprivate\nldbalance\n\ntype - The type parameter identifies the buffer type. Supported type\nmodes for the datawarp plugin include:\n\ncache\nscratch\n\nMultiple persistent burst buffers may be created or deleted within a single\njob.Example - Creating two persistent burst buffers:\n#!/bin/bash\n#BB create_persistent name=alpha capacity=32GB access=striped type=scratch\n#BB create_persistent name=beta capacity=16GB access=striped type=scratch\nsrun application.sh\nExample - Destroying two persistent burst buffers:\n#!/bin/bash\n#BB destroy_persistent name=alpha\n#BB destroy_persistent name=beta\nsrun application.sh\nPersistent burst buffers can be created and deleted by a job requiring no\ncompute resources. Submit a job with the desired burst buffer directives and\nspecify a node count of zero (e.g. sbatch -N0 setup_buffers.bash).\nAttempts to submit a zero size job without burst buffer directives or with\njob-specific burst buffer directives will generate an error. Note that zero\nsize jobs are not supported for job arrays or heterogeneous job\nallocations.NOTE: The ability to create and destroy persistent burst buffers may\nbe limited by the Flags option in the burst_buffer.conf file.\nSee the burst_buffer.conf man page for\nmore information.\nBy default only privileged users\n(i.e. Slurm operators and administrators)\ncan create or destroy persistent burst buffers.Heterogeneous Job Support\n\nHeterogeneous jobs may request burst buffers. Burst buffer hooks will run\nonce for each component that has burst buffer directives. For example, if a\nheterogeneous job has three components and two of them have burst buffer\ndirectives, the burst buffer hooks will run once for each of the two components\nwith burst buffer directives, but not for the third component without burst\nbuffer directives. Further information and examples can be found in the\nheterogeneous jobs page.\nCommand-line Job Options\n\nIn addition to putting burst buffer directives in the batch script, the\ncommand-line options --bb and --bbf may also include\nburst buffer directives. These command-line options are available for salloc,\nsbatch, and srun. Note that the --bb option cannot create or\ndestroy persistent burst buffers.The --bbf option takes as an argument a filename and that file\nshould contain a collection of burst buffer operations identical to those used\nfor batch jobs.Alternatively, the --bb option may be used to specify burst\nbuffer directives as the option argument. The behavior of this option depends\non which burst buffer plugin is used. When the --bb option is\nused, Slurm parses this option and creates a temporary burst buffer script file\nthat is used internally by the burst buffer plugins.Datawarp\n\nWhen using the --bb option, the format of the directives can\neither be identical to those used in a batch script OR a very limited set of\noptions can be used, which are translated to the equivalent script for later\nprocessing. The following options are allowed:\naccess=&ltaccess>\ncapacity=&ltnumber>\nswap=&ltnumber>\ntype=&lttype>\npool=&ltname>\nMultiple options should be space separated. If a swap option is specified,\nthe job must also specify the required node count.Example:\n# Sample execute line:\nsrun --bb=\"capacity=1G access=striped type=scratch\" a.out\n\n# Equivalent script as generated by Slurm's burst_buffer/datawarp plugin\n#DW jobdw capacity=1GiB access_mode=striped type=scratch\nLua\n\nThis plugin does not do any special parsing or translating of burst buffer\ndirectives given by the --bb option. When using the\n--bb option, the format is identical to the batch script: Slurm\nonly enforces that the burst buffer directive must be specified. See additional\ninformation in the Lua subsection of Job Submission\nCommands.Example:\n# Sample execute line:\nsrun --bb=\"#BB_LUA pool=pool1 capacity=1K\"\n\n# Equivalent script as generated by Slurm's burst_buffer/lua plugin\n#BB_LUA pool=pool1 capacity=1K\nSymbol Replacement\n\nSlurm supports a number of symbols that can be used to automatically\nfill in certain job details, e.g. to make stage-in or stage-out directory\npaths vary with each job submission.Supported symbols include:\n\n\n%%%\n%AArray Master Job Id\n%aArray Task Id\n%dWorkdir\n%jJob Id\n%uUser Name\n%xJob Name\n\\\\Stop further processing of the line\n\nStatus CommandsBurst buffer information that Slurm tracks is available by using the\nscontrol show burst command or by using the sview command's\nBurst Buffer tab. Examples follow.Datawarp plugin example:\n$ scontrol show burst\nName=datawarp DefaultPool=wlm_pool Granularity=200GiB TotalSpace=5800GiB FreeSpace=4600GiB UsedSpace=1600GiB\n  Flags=EmulateCray\n  StageInTimeout=86400 StageOutTimeout=86400 ValidateTimeout=5 OtherTimeout=300\n  GetSysState=/home/marshall/slurm/master/install/c1/sbin/dw_wlm_cli\n  GetSysStatus=/home/marshall/slurm/master/install/c1/sbin/dwstat\n  Allocated Buffers:\n    JobID=169509 CreateTime=2021-08-11T10:19:06 Pool=wlm_pool Size=1200GiB State=allocated UserID=marshall(1017)\n    JobID=169508 CreateTime=2021-08-11T10:18:46 Pool=wlm_pool Size=400GiB State=staged-in UserID=marshall(1017)\n  Per User Buffer Use:\n    UserID=marshall(1017) Used=1600GiB\nLua plugin example:\n$ scontrol show burst\nName=lua DefaultPool=(null) Granularity=1 TotalSpace=0 FreeSpace=0 UsedSpace=0\n  PoolName[0]=pool1 Granularity=1KiB TotalSpace=10000KiB FreeSpace=9750KiB UsedSpace=250KiB\n  PoolName[1]=pool2 Granularity=2 TotalSpace=10 FreeSpace=10 UsedSpace=0\n  PoolName[2]=pool3 Granularity=1 TotalSpace=4 FreeSpace=4 UsedSpace=0\n  PoolName[3]=pool4 Granularity=1 TotalSpace=5GB FreeSpace=4GB UsedSpace=1GB\n  Flags=DisablePersistent\n  StageInTimeout=86400 StageOutTimeout=86400 ValidateTimeout=5 OtherTimeout=300\n  GetSysState=(null)\n  GetSysStatus=(null)\n  Allocated Buffers:\n    JobID=169504 CreateTime=2021-08-11T10:13:38 Pool=pool1 Size=250KiB State=allocated UserID=marshall(1017)\n    JobID=169502 CreateTime=2021-08-11T10:12:06 Pool=pool4 Size=1GB State=allocated UserID=marshall(1017)\n  Per User Buffer Use:\n    UserID=marshall(1017) Used=1000256KB\nAccess to a burst buffer status API is available from scontrol using the\nscontrol show bbstat ... or scontrol show dwstat ...\ncommands. Options following bbstat or dwstat on the\nscontrol execute line are passed directly to the bbstat or dwstat commands, as\nshown below. In the datawarp plugin, this command calls Cray's dwstat script.\nSee Cray Datawarp documentation for details about dwstat options and output. In\nthe lua plugin, this command calls the slurm_bb_get_status\nfunction in burst_buffer.lua.Datawarp plugin example:\n/opt/cray/dws/default/bin/dwstat\n$ scontrol show dwstat\n    pool units quantity    free gran'\nwlm_pool bytes  7.28TiB 7.28TiB 1GiB'\n\n$ scontrol show dwstat sessions\n sess state      token creator owner             created expiration nodes\n  832 CA---  783000000  tester 12345 2015-09-08T16:20:36      never    20\n  833 CA---  784100000  tester 12345 2015-09-08T16:21:36      never     1\n  903 D---- 1875700000  tester 12345 2015-09-08T17:26:05      never     0\n\n$ scontrol show dwstat configurations\n conf state inst    type access_type activs\n  715 CA---  753 scratch      stripe      1\n  716 CA---  754 scratch      stripe      1\n  759 D--T-  807 scratch      stripe      0\n  760 CA---  808 scratch      stripe      1\nA Lua plugin example can be found in the slurm_bb_get_status\nfunction in the etc/burst_buffer.lua.example file provided\nwith Slurm.Advanced Reservations\n\nBurst buffer resources can be placed in an advanced reservation using the\nBurstBuffer option.\nThe argument consists of four elements:\n[plugin:][pool:]#[units]\n\nplugin is the burst buffer plugin name, currently either \"datawarp\"\nor \"lua\".\npool specifies a burst buffer resource pool.\nIf \"type\" is not specified, the number is a measure of storage space.\n# (meaning number) should be replaced with a positive integer.\nunits has the same format as the suffix of capacity in the\nJob Submission Commands section.\nJobs using this reservation are not restricted to these burst buffer\nresources, but may use these reserved resources plus any which are generally\navailable. Some examples follow.\n\n$ scontrol create reservation starttime=now duration=60 \\\n  users=alan flags=any_nodes \\\n  burstbuffer=datawarp:100G\n\n$ scontrol create reservation StartTime=noon duration=60 \\\n  users=brenda NodeCnt=8 \\\n  BurstBuffer=datawarp:20G\n\n$ scontrol create reservation StartTime=16:00 duration=60 \\\n  users=joseph flags=any_nodes \\\n  BurstBuffer=datawarp:pool_test:4G\n\nJob Dependencies\n\n\nIf two jobs use burst buffers and one is dependent on the other (e.g.\nsbatch --dependency=afterok:123 ...) then the second job will not\nbegin until the first job completes and its burst buffer stage-out completes.\nIf the second job does not use a burst buffer, but is dependent upon the first\njob's completion, then it will not wait for the stage-out operation of the first\njob to complete.\nThe second job can be made to wait for the first job's stage-out operation to\ncomplete using the \"afterburstbuffer\" dependency option (e.g.\nsbatch --dependency=afterburstbuffer:123 ...).\nBurst Buffer States and Job States\n\n\nThese are the different possible burst buffer states:\n\npending\nallocating\nallocated\ndeleting\ndeleted\nstaging-in\nstaged-in\npre-run\nalloc-revoke\nrunning\nsuspended\npost-run\nstaging-out\nteardown\nteardown-fail\ncomplete\n\nThese states appear in the \"BurstBufferState\" field in the output of\nscontrol show job. This field only appears for jobs that requested\na burst buffer. The states allocating, allocated,\ndeleting and deleted are used\nfor persistent burst buffers only (not for job-specific burst buffers). The\nstate alloc-revoke happens if a failure in Slurm's select plugin\noccurs in between Slurm allocating resources for a job and actually starting\nthe job. This should never happen.\nWhen a job requests a burst buffer, this is what the job and burst buffer\nstate transitions look like:\n\nJob is submitted. Job state and burst buffer state are both\npending.\nBurst buffer stage-in starts. Job state: pending with reason:\nBurstBufferStageIn. Burst buffer state: staging-in.\n\nWhen stage-in completes, the job is eligible to be scheduled (barring any\nother limits). Job state: pending. Burst buffer state:\nstaged-in.\nWhen the job is scheduled and allocated resources, the burst buffer pre-run\nstage begins. Job state: running+configuring. Burst buffer state:\npre-run.\nWhen pre-run finishes, the configuring flag is cleared from\nthe job and the job can actually start running. Job state and burst buffer\nstate are both running.\nWhen the job completes (even if it fails), burst buffer stage-out starts.\nJob state: stage-out. Burst buffer state:\nstaging-out.\nWhen stage-out completes, teardown starts. Job state: complete.\nBurst buffer state: teardown.\n\nThere are some situations which will change the state transitions. Examples\ninclude:\n\nBurst buffer operation failures:\n\nIf teardown fails, then the burst buffer state changes to\n\tteardown-fail.  Teardown will be retried. For the burst_buffer/lua\n\tplugin, teardown will run a maximum of 3 times before giving up and\n\tdestroying the burst buffer.\nIf either stage-in or stage-out fail and Flags=teardownFailure is\n\tconfigured in burst_buffer.conf, then teardown runs. Otherwise, the job\n\tis held and the burst buffer remains in the same state so it may be\n\tinspected and manually destroyed with scancel --hurry.\nIf pre-run fails, then the job is held and teardown runs.\n\nWhen a job is cancelled, the current burst buffer script for that job\n(if running) is killed. If scancel --hurry was used, or if the job\nnever ran, stage-out is skipped and it goes straight to teardown. Otherwise,\nstage-out begins.\nIf slurmctld is stopped, Slurm kills all running burst buffer scripts for\nall jobs and burst buffer state is saved for each job. When slurmctld restarts,\nfor each job it reads the burst buffer state and does one of the following:\n\nPending - Do nothing, since no burst buffer scripts were\n\tkilled.\nStaging-in, staged-in - run teardown, wait for a short time,\n\tthen restart stage-in.\nPre-run - Restart pre-run.\nRunning - Do nothing, since no burst buffer scripts were\n\tkilled.\nPost-run, staging-out - Restart post-run.\nTeardown, teardown-fail - Restart teardown.\n\n\nNOTE: There are many other things not listed here that affect the job\nstate. This document focuses on burst buffers and does not attempt to address\nall possible job state transitions.\nLast modified 21 August 2023\n"
        },
        {
            "title": "Navigation",
            "content": "\nSlurm Workload Manager\nVersion 24.05\n\n\nAbout\n\nOverview\nRelease Notes\n\n\n\nUsing\n\nDocumentation\nFAQ\nPublications\n\n\n\nInstalling\n\nDownload\nRelated Software\nInstallation Guide\n\n\n\nGetting Help\n\nMailing Lists\nSupport and Training\nTroubleshooting\n\n\n"
        },
        {
            "title": "Job Dependencies\n\n",
            "content": "If two jobs use burst buffers and one is dependent on the other (e.g.\nsbatch --dependency=afterok:123 ...) then the second job will not\nbegin until the first job completes and its burst buffer stage-out completes.\nIf the second job does not use a burst buffer, but is dependent upon the first\njob's completion, then it will not wait for the stage-out operation of the first\njob to complete.\nThe second job can be made to wait for the first job's stage-out operation to\ncomplete using the \"afterburstbuffer\" dependency option (e.g.\nsbatch --dependency=afterburstbuffer:123 ...).Burst Buffer States and Job States\n\nThese are the different possible burst buffer states:\npending\nallocating\nallocated\ndeleting\ndeleted\nstaging-in\nstaged-in\npre-run\nalloc-revoke\nrunning\nsuspended\npost-run\nstaging-out\nteardown\nteardown-fail\ncomplete\nThese states appear in the \"BurstBufferState\" field in the output of\nscontrol show job. This field only appears for jobs that requested\na burst buffer. The states allocating, allocated,\ndeleting and deleted are used\nfor persistent burst buffers only (not for job-specific burst buffers). The\nstate alloc-revoke happens if a failure in Slurm's select plugin\noccurs in between Slurm allocating resources for a job and actually starting\nthe job. This should never happen.When a job requests a burst buffer, this is what the job and burst buffer\nstate transitions look like:\nJob is submitted. Job state and burst buffer state are both\npending.\nBurst buffer stage-in starts. Job state: pending with reason:\nBurstBufferStageIn. Burst buffer state: staging-in.\n\nWhen stage-in completes, the job is eligible to be scheduled (barring any\nother limits). Job state: pending. Burst buffer state:\nstaged-in.\nWhen the job is scheduled and allocated resources, the burst buffer pre-run\nstage begins. Job state: running+configuring. Burst buffer state:\npre-run.\nWhen pre-run finishes, the configuring flag is cleared from\nthe job and the job can actually start running. Job state and burst buffer\nstate are both running.\nWhen the job completes (even if it fails), burst buffer stage-out starts.\nJob state: stage-out. Burst buffer state:\nstaging-out.\nWhen stage-out completes, teardown starts. Job state: complete.\nBurst buffer state: teardown.\nThere are some situations which will change the state transitions. Examples\ninclude:\nBurst buffer operation failures:\n\nIf teardown fails, then the burst buffer state changes to\n\tteardown-fail.  Teardown will be retried. For the burst_buffer/lua\n\tplugin, teardown will run a maximum of 3 times before giving up and\n\tdestroying the burst buffer.\nIf either stage-in or stage-out fail and Flags=teardownFailure is\n\tconfigured in burst_buffer.conf, then teardown runs. Otherwise, the job\n\tis held and the burst buffer remains in the same state so it may be\n\tinspected and manually destroyed with scancel --hurry.\nIf pre-run fails, then the job is held and teardown runs.\n\nWhen a job is cancelled, the current burst buffer script for that job\n(if running) is killed. If scancel --hurry was used, or if the job\nnever ran, stage-out is skipped and it goes straight to teardown. Otherwise,\nstage-out begins.\nIf slurmctld is stopped, Slurm kills all running burst buffer scripts for\nall jobs and burst buffer state is saved for each job. When slurmctld restarts,\nfor each job it reads the burst buffer state and does one of the following:\n\nPending - Do nothing, since no burst buffer scripts were\n\tkilled.\nStaging-in, staged-in - run teardown, wait for a short time,\n\tthen restart stage-in.\nPre-run - Restart pre-run.\nRunning - Do nothing, since no burst buffer scripts were\n\tkilled.\nPost-run, staging-out - Restart post-run.\nTeardown, teardown-fail - Restart teardown.\n\nNOTE: There are many other things not listed here that affect the job\nstate. This document focuses on burst buffers and does not attempt to address\nall possible job state transitions.Last modified 21 August 2023"
        }
    ]
}