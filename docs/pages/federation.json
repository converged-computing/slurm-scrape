{
    "url": "https://slurm.schedmd.com/federation.html",
    "sections": [
        {
            "title": "\n\nSlurm Workload Manager\n\n",
            "content": "\n\nSchedMD\n\n"
        },
        {
            "title": "Slurm Federated Scheduling Guide",
            "content": "\nOverview\nConfiguration\nFederated Job IDs\nJob Submission\nJob Scheduling\nJob Requeue\nInteractive Jobs\nCanceling Jobs\nJob Modification\nJob Arrays\nStatus Commands\nGlossary\nLimitations\nOverviewSlurm includes support for creating a federation of clusters\nand scheduling jobs in a peer-to-peer fashion between them. Jobs submitted to a\nfederation receive a unique job ID that is unique among all clusters in the\nfederation. A job is submitted to the local cluster (the cluster defined in the\nslurm.conf) and is then replicated across the clusters in the federation. Each\ncluster then independently attempts to the schedule the job based off of its own\nscheduling policies. The clusters coordinate with the \"origin\" cluster (cluster\nthe job was submitted to) to schedule the job.\n\n\nNOTE: This is not intended as a high-throughput environment. If\nscheduling more than 50,000 jobs a day, consider configuring fewer clusters that\nthe sibling jobs can be submitted to or directing load\nto the local cluster only (e.g. --cluster-constraint= or -M submission options\ncould be used to do this).\n\nConfiguration\n\n\n\nA federation is created using the sacctmgr command to create a federation in the\ndatabase and by adding clusters to a federation.\n\n\nTo create a federation use:\n\nsacctmgr add federation <federation_name> [clusters=<list_of_clusters>]\n\n\nClusters can be added or removed from a federation using:\n\nNOTE: A cluster can only be a member of one federation at a time.\n\nsacctmgr modify federation <federation_name> set clusters[+-]=<list_of_clusters>\nsacctmgr modify cluster <cluster_name> set federation=<federation_name>\nsacctmgr modify federation <federation_name> set clusters=\nsacctmgr modify cluster <cluster_name> set federation=\n\nNOTE: If a cluster is removed from a federation without first being\ndrained, running jobs on the removed cluster, or that originated from the\nremoved cluster, will continue to run as non-federated jobs. If a job is pending\non the origin cluster, the job will remain pending on the origin cluster as a\nnon-federated job and the remaining sibling jobs will be removed. If the origin\ncluster is being removed and the job is pending and is only viable on one\ncluster then it will remain pending on the viable cluster as a non-federated\njob. If the origin cluster is being removed and the job is pending and viable on\nmultiple clusters other than the origin cluster, then the remaining pending jobs\nwill remain pending as a federated job and the remaining sibling clusters will\nschedule amongst themselves to start the job.\n\n\n\nFederations can be deleted using:\n\nsacctmgr delete federation <federation_name>\n\n\n\nGeneric features can be assigned to clusters and can be requested at submission\nusing the --cluster-constraint=[!]<feature_list> option:\n\nsacctmgr modify cluster <cluster_name> set features[+-]=<feature_list>\n\n\nA cluster's federated state can be set using:\n\nsacctmgr modify cluster <cluster_name> set fedstate=<state>\n\nwhere possible states are:\n\nACTIVE: Cluster will actively accept and schedule federated\n\t\tjobs\nINACTIVE: Cluster will not schedule or accept any jobs\nDRAIN: Cluster will not accept any new jobs and will let\n\t\texisting federated jobs complete\nDRAIN+REMOVE: Cluster will not accept any new jobs and will\n\t\tremove itself from the federation once all federated jobs have\n\t\tcompleted. When removed from the federation, the cluster will\n\t\taccept jobs as a non-federated cluster\n\n\nFederation configuration can be viewed used using:\n\nsacctmgr show federation [tree]\nsacctmgr show cluster withfed\n\n\nAfter clusters are added to a federation and the controllers are started their\nstatus can be viewed from the controller using:\n\nscontrol show federation\n\n\n\nBy default the status commands will show a local view. A default federated view\ncan be set by configuring the following parameter in the slurm.conf:\n\nFederationParameters=fed_display\n\nFederated Job IDs\nWhen a job is submitted to a federation it gets a federated job id. Job ids in\nthe federation are unique across all clusters in the federation. A federated\njob ID is made by utilizing an unsigned 32 bit integer to assign the cluster's\nID and the cluster's local ID.\n\n\nBits 0-25:  Local Job ID\nBits 26-31: Cluster Origin ID\n\n\nFederated job IDs allow the controllers to know which cluster the job was\nsubmitted to by looking at the cluster origin id of the job.\n\n\nJob Submission\n\n\n\nWhen a federated cluster receives a job submission, it will submit copies of the\njob (sibling jobs) to each eligible cluster. Each cluster will then\nindependently attempt to schedule the job.\n\n\nJobs can be directed to specific clusters in the federation using the\n-M,--clusters=<cluster_list> and the new\n--cluster-constraint=[!]<constraint_list> options.\n\n\nUsing the -M,--clusters=<cluster_list> the submission command\n(sbatch, salloc, srun) will pick one cluster from the list of clusters to submit\nthe job to and will also pass along the list of clusters with the job. The\nclusters in the list will be the only viable clusters that siblings jobs can be\nsubmitted to. For example the submission:\n\ncluster1$ sbatch -Mcluster2,cluster3 script.sh\n\nwill submit the job to either cluster2 or cluster3 and will only submit sibling\njobs to cluster2 and cluster3 even if there are more clusters in the federation.\n\n\nUsing the --cluster-constraint=[!]<constraint_list> option will\nsubmit sibling jobs to only the clusters that have the requested cluster\nfeature(s) -- or don't have the feature(s) if using !. Cluster features\nare added using the sacctmgr modify cluster <cluster_name> set\nfeatures[+-]=<feature_list> option.\n\n\nNOTE: When using the ! option, add quotes around the option to\nprevent the shell from interpreting the ! (e.g\n--cluster-constraint='!highmem').\n\n\nWhen using both the --cluster-constraint= and\n--clusters= options together, the origin cluster will only submit\nsibling jobs to clusters that meet both requirements.\n\n\nHeld or dependent jobs are kept on the origin cluster until they are released\nor are no longer dependent, at which time they are submitted to other viable\nclusters in the federation. If a job becomes held or dependent\nafter being submitted, the job is removed from every cluster but the origin.\n\nJob Scheduling\n\n\n\nEach cluster in the federation independently attempts to schedule each job with\nthe exception of coordinating with the origin cluster (cluster where the\njob was submitted to) to allocate resources to a federated job. When a cluster\ndetermines it can attempt to allocate resources for a job it communicates with\nthe origin cluster to verify that no other cluster is attempting to allocate\nresources at the same time. If no other cluster is attempting to allocate\nresources the cluster will attempt to allocate resources for the job. If it\nsucceeds then it will notify the origin cluster that it started the job and the\norigin cluster will notify the clusters with sibling jobs to remove the sibling\njobs and put them in a revoked state. If the cluster was unable to\nallocate resources to the job then it lets the origin cluster know so that other\nclusters can attempt to schedule the job. If it was the main scheduler\nattempting to allocate resources then the main scheduler will stop looking at\nfurther jobs in the job's partition. If it was the backfill scheduler attempting\nto allocate resources then the resources will be reserved for the job.\n\n\nIf an origin cluster is down, then the remote siblings will coordinate with a\njob's viable siblings to schedule the job. When the origin cluster comes back\nup, it will sync with the other siblings.\n\nJob Requeue\n\n\n\nWhen a federated job is requeued the origin cluster is notified and the origin\ncluster will then submit new sibling jobs to viable clusters and the federated\njob is eligible to start on a different cluster than the one it ran on.\n\n\nslurm.conf options RequeueExit and RequeueExitHold are controlled\nby the origin cluster.\n\nInteractive Jobs\n\n\n\nInteractive jobs -- jobs submitted with srun and salloc -- can be submitted to\nthe local cluster and get an allocation from a different cluster. When an salloc\njob allocation is granted by a cluster other than the local cluster, a new\nenvironment variable, SLURM_WORKING_CLUSTER, will be set with the remote sibling\ncluster's IP address, port and RPC version so that any sruns will know which\ncluster to communicate with.\n\n\nNOTE: It is required that all compute nodes must be accessible to all\nsubmission hosts for this to work.\n\nNOTE: The current implementation of the MPI interfaces in Slurm require\nthe SlurmdSpooldir to be the same on the host where the srun is being run as it\nis on the compute nodes in the allocation. If they aren't, a workaround is to\nget an allocation that puts the user on the actual compute node. Then the sruns\non the compute nodes will be using the slurm.conf that corresponds to the\ncorrect cluster. Setting LaunchParameters=use_interactive_step\nslurm.conf will put the user on an actual compute node when using salloc.\n\nCanceling Jobs\n\n\n\nCancel requests in the federation will cancel the running sibling job or all\npending sibling jobs. Specific pending sibling jobs can be removed by using\nscancel's --sibling=<cluster_name> option to remove the\nsibling job from the job's active sibling list.\n\nJob Modification\n\n\nJob modifications are routed to the origin cluster where the origin cluster will\npush out the changes to each sibling job.\n\n\nJob Arrays\nCurrently, job arrays only run on the origin cluster.\n\n\nStatus Commands\n\n\n\nBy default, status commands, such as: squeue, sinfo, sprio, sacct, sreport, will\nshow a view local to the local cluster. A unified view of the jobs in the\nfederation can be viewed using the --federation option to each status\ncommand. The --federation command causes the status command to first\ncheck if the local cluster is part of a federation. If it is then the command\nwill query each cluster in parallel for job info and will combine the\ninformation into one unified view.\n\n\nA new FederationParameters=fed_display slurm.conf parameter has been\nadded so that all status commands will present a federated view by default --\nequivalent to setting the --federation option for each status command.\nThe federated view can be overridden using the --local option. Using the\n--clusters,-M option will also override the federated view and give a\nlocal view for the given cluster(s).\n\n\nUsing the existing --clusters,-M option, the status commands will output\nthe information in the same format that exists today where each cluster's\ninformation is listed separately.\n\nsqueue\n\nsqueue also has a new --sibling option that will show each sibling job\nrather than merge them into one.\n\n\nSeveral new long format options have been added to display the job's federated\ninformation:\n\n\ncluster: Name of the cluster that is running the job or\n\t\tjob step.\n\t\n\nsiblingsactive: Cluster names of where federated sibling\n\t\tjobs exist.\n\t\n\nsiblingsactiveraw: Cluster IDs of where federated\n\t\tsibling jobs exist.\n\t\n\nsiblingsviable: Cluster names of where federated sibling\n\t\tjobs are viable to run.\n\t\n\nsiblingsviableraw: Cluster names of where federated\n\t\tsibling jobs are viable to run.\n\t\n\n\n\nsqueue output can be sorted using the -S cluster option.\n\nsinfo\n\nsinfo will show the partitions from each cluster in one view. In a federated\nview, the cluster name is displayed with each partition. The cluster name can be\nspecified in the format options using the short format %V or the long\nformat cluster options. The output can be sorted by cluster names using\nthe -S %[+-]V option.\n\nsprio\n\nIn a federated view, sprio displays the job information from the local cluster\nor from the first cluster to report the job. Since each sibling job could have a\ndifferent priority on each cluster it may be helpful to use the --sibling\noption to show all records of a job to get a better picture of a job's priority.\nThe name of the cluster reporting the job record can be displayed using the\n%c format option. The cluster name is shown by default when using\n--sibling option.\n\nsacct\n\nBy default, sacct will not display \"revoked\" jobs and will show the job from the\ncluster that ran the job. However, \"revoked\" jobs can be viewed using the\n--duplicate/-D option.\n\nsreport\n\nsreport will combine the reports from each cluster and display them as one.\n\nscontrol\n\nThe following scontrol options will display a federated view:\n\nshow [--federation|--sibling] jobs\nshow [--federation] steps\ncompleting\n\n\n\nThe following scontrol options are handled in a federation. If the command is\nrun from a cluster other than the federated cluster it will be routed to the\norigin cluster.\n\nhold\nuhold\nrelease\nrequeue\nrequeuehold\nsuspend\nupdate job\n\n\n\nAll other scontrol options should be directed to the specific cluster either by\nissuing the command on the cluster or using the --cluster/-M  option.\n\nGlossary\n\n\nFederated Job: A job that is submitted to the federated\n\t\tcluster. It has a unique job ID across all clusters (Origin\n\t\tCluster ID + Local Job ID).\n\t\n\nSibling Job: A copy of the federated job that is\n\t\tsubmitted to other federated clusters.\n\t\n\nLocal Cluster: The cluster found in the slurm.conf that\n\t\tthe commands will talk to by default.\n\t\n\nOrigin Cluster: The cluster that the federated job was\n\t\toriginally submitted to. The origin cluster submits sibling jobs\n\t\tto other clusters in the federation. The origin cluster\n\t\tdetermines whether a sibling job can run or not. Communications\n\t\tfor the federated job are routed through the origin cluster.\n\t\n\nSibling Cluster: The cluster that is associated with a\n\t\tsibling job.\n\t\n\nOrigin Job: The federated job that resides on the cluster\n\t\tthat it was originally submitted to.\n\t\n\nRevoked (RV) State: The state that the origin job is in\n\t\twhile the origin job is not actively being scheduled on the\n\t\torigin cluster (e.g. not a viable sibling or one of the sibling\n\t\tjobs is running on a remote cluster). Or the state that a remote\n\t\tsibling job is put in when another sibling is allocated nodes.\n\t\n\nViable Sibling: a cluster that is eligible to run a\n\t\tsibling job based off of the requested clusters, cluster\n\t\tfeatures and state of the cluster (e.g. active, draining, etc.).\n\t\n\nActive Sibling: a sibling job that actively has a\n\t\tsibling job and is able to schedule the job.\n\t\n\nLimitations\n\n\n\nA federated job that fails due to resources (partition, node counts,\n\t\tetc.) on the local cluster will be rejected and won't be\n\t\tsubmitted to other sibling clusters even if it could run on\n\t\tthem.\nJob arrays only run on the cluster that they were submitted to.\nJob modification must succeed on the origin cluster for the changes\n\t\tto be pushed to the sibling jobs on remote clusters. \nModifications to anything other than jobs are disabled in sview.\nsview grid is disabled in a federated view.\n\nLast modified 9 June 2021\n"
        },
        {
            "title": "Navigation",
            "content": "\nSlurm Workload Manager\nVersion 24.05\n\n\nAbout\n\nOverview\nRelease Notes\n\n\n\nUsing\n\nDocumentation\nFAQ\nPublications\n\n\n\nInstalling\n\nDownload\nRelated Software\nInstallation Guide\n\n\n\nGetting Help\n\nMailing Lists\nSupport and Training\nTroubleshooting\n\n\n"
        },
        {
            "title": "Configuration\n\n",
            "content": "\nA federation is created using the sacctmgr command to create a federation in the\ndatabase and by adding clusters to a federation.\n\nsacctmgr add federation <federation_name> [clusters=<list_of_clusters>]\nNOTE\nsacctmgr modify federation <federation_name> set clusters[+-]=<list_of_clusters>\nsacctmgr modify cluster <cluster_name> set federation=<federation_name>\nsacctmgr modify federation <federation_name> set clusters=\nsacctmgr modify cluster <cluster_name> set federation=\nNOTE\nsacctmgr delete federation <federation_name>\n--cluster-constraint=[!]<feature_list>\nsacctmgr modify cluster <cluster_name> set features[+-]=<feature_list>\n\nsacctmgr modify cluster <cluster_name> set fedstate=<state>\n\nACTIVE: Cluster will actively accept and schedule federated\n\t\tjobs\nINACTIVE: Cluster will not schedule or accept any jobs\nDRAIN: Cluster will not accept any new jobs and will let\n\t\texisting federated jobs complete\nDRAIN+REMOVE: Cluster will not accept any new jobs and will\n\t\tremove itself from the federation once all federated jobs have\n\t\tcompleted. When removed from the federation, the cluster will\n\t\taccept jobs as a non-federated cluster\n\nsacctmgr show federation [tree]\nsacctmgr show cluster withfed\n\nscontrol show federation\n\nFederationParameters=fed_display\nFederated Job IDs\nBits 0-25:  Local Job ID\nBits 26-31: Cluster Origin ID\nJob Submission\n\n\nWhen a federated cluster receives a job submission, it will submit copies of the\njob (sibling jobs) to each eligible cluster. Each cluster will then\nindependently attempt to schedule the job.\n\nJobs can be directed to specific clusters in the federation using the\n-M,--clusters=<cluster_list> and the new\n--cluster-constraint=[!]<constraint_list> options.\n\nUsing the -M,--clusters=<cluster_list> the submission command\n(sbatch, salloc, srun) will pick one cluster from the list of clusters to submit\nthe job to and will also pass along the list of clusters with the job. The\nclusters in the list will be the only viable clusters that siblings jobs can be\nsubmitted to. For example the submission:\n\ncluster1$ sbatch -Mcluster2,cluster3 script.sh\n\nwill submit the job to either cluster2 or cluster3 and will only submit sibling\njobs to cluster2 and cluster3 even if there are more clusters in the federation.\n\nUsing the --cluster-constraint=[!]<constraint_list> option will\nsubmit sibling jobs to only the clusters that have the requested cluster\nfeature(s) -- or don't have the feature(s) if using !. Cluster features\nare added using the sacctmgr modify cluster <cluster_name> set\nfeatures[+-]=<feature_list> option.\n\nNOTE: When using the ! option, add quotes around the option to\nprevent the shell from interpreting the ! (e.g\n--cluster-constraint='!highmem').\n\nWhen using both the --cluster-constraint= and\n--clusters= options together, the origin cluster will only submit\nsibling jobs to clusters that meet both requirements.\n\nHeld or dependent jobs are kept on the origin cluster until they are released\nor are no longer dependent, at which time they are submitted to other viable\nclusters in the federation. If a job becomes held or dependent\nafter being submitted, the job is removed from every cluster but the origin.\nJob Scheduling\n\n\nEach cluster in the federation independently attempts to schedule each job with\nthe exception of coordinating with the origin cluster (cluster where the\njob was submitted to) to allocate resources to a federated job. When a cluster\ndetermines it can attempt to allocate resources for a job it communicates with\nthe origin cluster to verify that no other cluster is attempting to allocate\nresources at the same time. If no other cluster is attempting to allocate\nresources the cluster will attempt to allocate resources for the job. If it\nsucceeds then it will notify the origin cluster that it started the job and the\norigin cluster will notify the clusters with sibling jobs to remove the sibling\njobs and put them in a revoked state. If the cluster was unable to\nallocate resources to the job then it lets the origin cluster know so that other\nclusters can attempt to schedule the job. If it was the main scheduler\nattempting to allocate resources then the main scheduler will stop looking at\nfurther jobs in the job's partition. If it was the backfill scheduler attempting\nto allocate resources then the resources will be reserved for the job.\n\nIf an origin cluster is down, then the remote siblings will coordinate with a\njob's viable siblings to schedule the job. When the origin cluster comes back\nup, it will sync with the other siblings.\nJob Requeue\n\n\nWhen a federated job is requeued the origin cluster is notified and the origin\ncluster will then submit new sibling jobs to viable clusters and the federated\njob is eligible to start on a different cluster than the one it ran on.\n\nslurm.conf options RequeueExit and RequeueExitHold are controlled\nby the origin cluster.\nInteractive Jobs\n\n\nInteractive jobs -- jobs submitted with srun and salloc -- can be submitted to\nthe local cluster and get an allocation from a different cluster. When an salloc\njob allocation is granted by a cluster other than the local cluster, a new\nenvironment variable, SLURM_WORKING_CLUSTER, will be set with the remote sibling\ncluster's IP address, port and RPC version so that any sruns will know which\ncluster to communicate with.\n\nNOTE: It is required that all compute nodes must be accessible to all\nsubmission hosts for this to work.\n\nNOTE: The current implementation of the MPI interfaces in Slurm require\nthe SlurmdSpooldir to be the same on the host where the srun is being run as it\nis on the compute nodes in the allocation. If they aren't, a workaround is to\nget an allocation that puts the user on the actual compute node. Then the sruns\non the compute nodes will be using the slurm.conf that corresponds to the\ncorrect cluster. Setting LaunchParameters=use_interactive_step\nslurm.conf will put the user on an actual compute node when using salloc.\nCanceling Jobs\n\n\nCancel requests in the federation will cancel the running sibling job or all\npending sibling jobs. Specific pending sibling jobs can be removed by using\nscancel's --sibling=<cluster_name> option to remove the\nsibling job from the job's active sibling list.\nJob Modification\n\nJob ArraysStatus Commands\n\n\nBy default, status commands, such as: squeue, sinfo, sprio, sacct, sreport, will\nshow a view local to the local cluster. A unified view of the jobs in the\nfederation can be viewed using the --federation option to each status\ncommand. The --federation command causes the status command to first\ncheck if the local cluster is part of a federation. If it is then the command\nwill query each cluster in parallel for job info and will combine the\ninformation into one unified view.\n\nA new FederationParameters=fed_display slurm.conf parameter has been\nadded so that all status commands will present a federated view by default --\nequivalent to setting the --federation option for each status command.\nThe federated view can be overridden using the --local option. Using the\n--clusters,-M option will also override the federated view and give a\nlocal view for the given cluster(s).\n\nUsing the existing --clusters,-M option, the status commands will output\nthe information in the same format that exists today where each cluster's\ninformation is listed separately.\nsqueue\nsqueue also has a new --sibling option that will show each sibling job\nrather than merge them into one.\n\nSeveral new long format options have been added to display the job's federated\ninformation:\n\n\ncluster: Name of the cluster that is running the job or\n\t\tjob step.\n\t\n\nsiblingsactive: Cluster names of where federated sibling\n\t\tjobs exist.\n\t\n\nsiblingsactiveraw: Cluster IDs of where federated\n\t\tsibling jobs exist.\n\t\n\nsiblingsviable: Cluster names of where federated sibling\n\t\tjobs are viable to run.\n\t\n\nsiblingsviableraw: Cluster names of where federated\n\t\tsibling jobs are viable to run.\n\t\n\n\nsqueue output can be sorted using the -S cluster option.\nsinfo\nsinfo will show the partitions from each cluster in one view. In a federated\nview, the cluster name is displayed with each partition. The cluster name can be\nspecified in the format options using the short format %V or the long\nformat cluster options. The output can be sorted by cluster names using\nthe -S %[+-]V option.\nsprio\nIn a federated view, sprio displays the job information from the local cluster\nor from the first cluster to report the job. Since each sibling job could have a\ndifferent priority on each cluster it may be helpful to use the --sibling\noption to show all records of a job to get a better picture of a job's priority.\nThe name of the cluster reporting the job record can be displayed using the\n%c format option. The cluster name is shown by default when using\n--sibling option.\nsacct\nBy default, sacct will not display \"revoked\" jobs and will show the job from the\ncluster that ran the job. However, \"revoked\" jobs can be viewed using the\n--duplicate/-D option.\nsreport\nsreport will combine the reports from each cluster and display them as one.\nscontrol\nThe following scontrol options will display a federated view:\n\nshow [--federation|--sibling] jobs\nshow [--federation] steps\ncompleting\n\n\nThe following scontrol options are handled in a federation. If the command is\nrun from a cluster other than the federated cluster it will be routed to the\norigin cluster.\n\nhold\nuhold\nrelease\nrequeue\nrequeuehold\nsuspend\nupdate job\n\n\nAll other scontrol options should be directed to the specific cluster either by\nissuing the command on the cluster or using the --cluster/-M  option.\nGlossary\n\nFederated Job: A job that is submitted to the federated\n\t\tcluster. It has a unique job ID across all clusters (Origin\n\t\tCluster ID + Local Job ID).\n\t\n\nSibling Job: A copy of the federated job that is\n\t\tsubmitted to other federated clusters.\n\t\n\nLocal Cluster: The cluster found in the slurm.conf that\n\t\tthe commands will talk to by default.\n\t\n\nOrigin Cluster: The cluster that the federated job was\n\t\toriginally submitted to. The origin cluster submits sibling jobs\n\t\tto other clusters in the federation. The origin cluster\n\t\tdetermines whether a sibling job can run or not. Communications\n\t\tfor the federated job are routed through the origin cluster.\n\t\n\nSibling Cluster: The cluster that is associated with a\n\t\tsibling job.\n\t\n\nOrigin Job: The federated job that resides on the cluster\n\t\tthat it was originally submitted to.\n\t\n\nRevoked (RV) State: The state that the origin job is in\n\t\twhile the origin job is not actively being scheduled on the\n\t\torigin cluster (e.g. not a viable sibling or one of the sibling\n\t\tjobs is running on a remote cluster). Or the state that a remote\n\t\tsibling job is put in when another sibling is allocated nodes.\n\t\n\nViable Sibling: a cluster that is eligible to run a\n\t\tsibling job based off of the requested clusters, cluster\n\t\tfeatures and state of the cluster (e.g. active, draining, etc.).\n\t\n\nActive Sibling: a sibling job that actively has a\n\t\tsibling job and is able to schedule the job.\n\t\nLimitations\n\n\nA federated job that fails due to resources (partition, node counts,\n\t\tetc.) on the local cluster will be rejected and won't be\n\t\tsubmitted to other sibling clusters even if it could run on\n\t\tthem.\nJob arrays only run on the cluster that they were submitted to.\nJob modification must succeed on the origin cluster for the changes\n\t\tto be pushed to the sibling jobs on remote clusters. \nModifications to anything other than jobs are disabled in sview.\nsview grid is disabled in a federated view.\nLast modified 9 June 2021"
        }
    ]
}