{
    "url": "https://slurm.schedmd.com/upgrades.html",
    "sections": [
        {
            "title": "\n\nSlurm Workload Manager\n\n",
            "content": "\n\nSchedMD\n\n"
        },
        {
            "title": "Upgrade Guide",
            "content": "Slurm supports in-place upgrades between certain versions. This page provides\nimportant details about the steps necessary to perform an upgrade and the\npotential complications to prepare for.See also Quick Start Administrator GuideContents\nRelease Cycle\n\nCompatibility Window\nEPEL Repository\nPre-Release Versions\n\nReverting an Upgrade\nMinor Upgrades\nUpgrade Procedure\n\nPreparation\nCreate Backups\nslurmdbd (Accounting)\n\nDatabase Server\n\nslurmctld (Controller)\nslurmd (Compute Nodes)\nOther Slurm Commands\nCustomized Slurm Plugins\n\nSeamless Upgrades\nRelease Cycle\nThe Slurm version number contains three period-separated numbers that\nrepresent both the major Slurm release and maintenance release level.\nFor example, Slurm 23.11.4:\n23.11 = major release\n\nThis matches the year and month of initial release (November 2023)\nMajor releases may contain changes to RPCs (remote procedure calls),\n\tstate files, configuration options, and core functionality\n\n.4 = maintenance version\n\nMaintenance releases may contain bug fixes and performance improvements\n\nPrior to the 24.05 release, Slurm operated on a 9-month release cycle for\nmajor versions. Slurm 24.05 represents the first release on the\n\nnew 6-month cycle.Compatibility Window\nUpgrades from the previous two major releases are compatible. For\nexample, slurmdbd 23.11.x is capable of accepting messages from slurmctld\ndaemons and commands with a version of 23.11.x, 23.02.x or 22.05.x. It is also\ncapable of updating the records in the database that were recorded by an\ninstance of slurmdbd running these versions.The Slurm 24.11 release will introduce compatibility with three previous\nmajor releases to provide a similar support duration with the more frequent\n6-month release cycle:\n\n\nSlurm Release\nRevised End of Support(total length)\nCompatible Prior Version\n\n\n23.02\nNovember 2024 (21 months)\n22.05, 21.08\n\n\n23.11\nMay 2025 (18 months)\n23.02, 22.05\n\n\n24.05\nNovember 2025 (18 months)\n23.11, 23.02\n\n\n24.11\nMay 2026 (18 months)\n24.05, 23.11, 23.02\n\n\n25.05\nNovember 2026 (18 months)\n24.11, 24.05, 23.11\n\n\n25.11\nMay 2027 (18 months)\n25.05, 24.11, 24.05\n\n\nUpgrades from incompatible versions will fail immediately upon startup.\nIt is required to perform upgrades from incompatible prior versions in steps,\ngoing to newer versions compatible with the current running version. It may\ntake several steps to upgrade to a current release of Slurm. For example,\ninstead of upgrading directly from Slurm 20.11 to 23.11, first upgrade all\nsystems to Slurm 22.05 and verify functionality, then proceed to upgrade to\n23.11. This ensures that each upgrade performed is tested and can be supported\nby SchedMD. Compatibility requirements apply to running jobs and upgrading\noutside of their compatibility window will result in the jobs being killed and\njob accounting being lost.EPEL Repository\nIn the beginning of 2021, a version of Slurm was added to the\nEPEL repository. This version is not provided by or supported by SchedMD, and is\nnot currently supported for customer use. Unfortunately, this inclusion could\ncause Slurm to be updated to a newer version outside of a planned maintenance\nperiod or result in conflicting packages. In order to prevent Slurm from being\nchanged and broken unintentionally, we recommend you modify the EPEL Repository\nconfiguration to exclude all Slurm packages from automatic updates.Add the following under the [epel]\nsection of /etc/yum.repos.d/epel.repo:\nexclude=slurm*Pre-Release Versions\nWhen installing pre-release versions (e.g., 24.05.0rc1 or\nmaster branch), you should prepare\nfor unexpected crashes, bugs, and loss of state information. SchedMD aims to\nuse the NEWS file to indicate cases in which state information will be lost with\npre-release versions. However, these pre-release versions receive limited\ntesting and are not intended for production clusters. Sites are encouraged\nto actively run pre-release versions on test machines before each major release.\nReverting an Upgrade\nReverting an upgrade (or downgrading) is not supported once any of the\nSlurm daemons have been started. When starting up after an upgrade, the Slurm\ndaemons (slurmctld, slurmdbd, and slurmd) will update their relevant state\nfiles and databases to the structure used in the new version. If you revert to\nan older version, the relevant Slurm daemon will not recognize the new state\nfile or database, resulting in loss or corruption of state information or job\naccounting. The Slurm daemons will likely refuse to start unless configured to\nstart with the risk of possible data loss.By using recovery tools, like comprehensive file backups, disk images, and\nsnapshots, it may be possible to revert components to the pre-upgrade state.\nIn particular, restoring the contents of StateSaveLocation (as defined in\nslurm.conf) and (if configured) the accounting database will be required\nif you wish to revert an upgrade. Reverting an upgrade will wipe out anything\nthat happened after the backups were created.Minor Upgrades\nWhen upgrading to a newer minor maintenance release (as\ndefined above), we recommend following the same\nupgrade procedure as with major releases. You will find that the process takes\nless time, and is more accommodating of mixed versions and in-place\ndowngrades. However, you should always have current backups to solidify your\nrecovery options.Upgrade Procedure\nThe upgrades procedure can be summarized as follows. Note the specific order\nin which the daemons should be upgraded:\nPrepare cluster for the upgrade\nCreate backups\nUpgrade slurmdbd\nUpgrade slurmctld\nUpgrade slurmd (preferably with slurmctld)\nUpgrade login nodes and client commands\nRecompile/upgrade customized Slurm plugins\nTest key functionality\nArchive backup data\nBefore considering the upgrade complete, wait for all jobs that were already\nrunning to finish. Any jobs started before the slurmd system was upgraded\nwill be running with the old version of slurmstepd, so starting another\nupgrade or trying to use new features in the new version may cause problems.NOTE: If multiple daemons are present on the same system, they may\nneed to be upgraded at the same time due to dependencies to the general\nslurm package. After upgrading, daemons should be started in the order\nlisted above. This is not a recommended setup for production; sites are\nstrongly advised to assign a single core Slurm daemon to each system.Preparation\nRELEASE_NOTES and NEWS\nReview relevant release notes in the RELEASE_NOTES file in root of\nSlurm source directory for the target release and any major versions between\nwhat you're currently running and the target you are upgrading to. Pay\nparticular attention to any entries in which items are removed or\nchanged. These are particularly likely to require specific attention or\nchanges during the upgrade. Also look for changes in optional slurm components\nthat you are using. You may also notice new items added to Slurm that you wish\nto start using after the upgrade.Release notes for the latest major version are\navailable here. Release notes for other\nversions can be found in the source, which can be viewed on\nGitHub\nby selecting the branch or tag corresponding to the desired version. More\ndetailed changes, including minor release changes, can be found in the\nNEWS file, but are usually not needed to prepare for upgrades.Configuration Changes\nAlways prepare and test configuration changes in a test environment\nbefore upgrading in production. Changes outlined in the release notes will need\nto be looked up in the man pages (such as slurm.conf\n) for details and new syntax. Certain options in your configuration files\nmay need to be changed as features and functionality are improved in every major\nSlurm release. Typically, new naming and syntax conventions are introduced\nseveral versions before the old ones are removed, so you may be able to make the\nnecessary changes before starting the upgrade process.Plan for Downtime\nRefer to the expected downtime guidance in the\nfollowing sections for each relevant Slurm daemon, particularly the\nslurmdbd. Notify affected users of the estimated\ndowntime for the relevant services and the potential impact on their jobs.\nWhenever possible, try to plan upgrades during SchedMD's support hours.\nIf you encounter an issue outside of these hours there will be a delay before\nassistance can be provided.OpenAPI Changes\nSites using --json or --yaml arguments with any CLI\ncommands or running slurmrestd need to check for format\ncompatibility and data_parser plugin removals before upgrading. The formats for\nthe values parsed and dumped as JSON and YAML are handled by the data_parser\nand openapi plugins. Changes to the formats are tracked in the\nOpenAPI release notes.\n\n\nRelease Notes\nAdded OpenAPI plugins\nAdded Data_Parser plugin\nRemoved in Release\n\n\n20.02\nv0.0.35,dbv0.0.35\n\n22.05\n\n\n20.11\nv0.0.36, dbv0.0.36\n\n23.02\n\n\n21.08\nv0.0.37, dbv0.0.37\n\n23.11\n\n\n22.05\nv0.0.38, dbv0.0.38\n\n24.05\n\n\n23.02\nv0.0.39, dbv0.0.39\nv0.0.39\n24.11\n\n\n23.11\nslurmctld, slurmdbd\nv0.0.40\n25.05\n\n\n24.05\n\nv0.0.41\n25.11\n\n\n24.11\n\nv0.0.42\n26.05\n\n\nNOTE: The unversioned openapi/slurmctld and openapi/slurmdbd plugins\nhave no planned removal release.Any scripts or clients making use of --json or\n--yaml arguments with any CLI commands may need to pass the\ndata_parser version explicitly to avoid issues after an upgrade. The default\ndata_parser used is the latest version which may not have a compatible format\nwith the prior versions. Sites can use the specification generation mode to\ncompare formatting differences.\n\n$CLI_COMMAND --json=v0.0.41+spec_only > /tmp/v41.json;\n$CLI_COMMAND --json=v0.0.40+spec_only > /tmp/v40.json;\njson_diff /tmp/v40.json /tmp/v41.json;\nIn the event of a format incompatibility, the preferred data_parser can be\nrequested explicitly starting with the v0.0.40 plugins in any release before\nthe plugin's removal.\n\n$CLI_COMMAND --json=v0.0.41 $OTHER_ARGS | $SITE_SCRIPT;\n$CLI_COMMAND --json=v0.0.40 $OTHER_ARGS | $SITE_SCRIPT;\n$CLI_COMMAND --yaml=v0.0.41 $OTHER_ARGS | $SITE_SCRIPT;\n$CLI_COMMAND --yaml=v0.0.40 $OTHER_ARGS | $SITE_SCRIPT;\nAny slurmrestd web clients can determine the relevant plugin\nbeing used by looking at the URL being queried. Example URLs:\n\nhttp://$HOST/slurmdb/v0.0.40/jobs\nhttp://$HOST/slurm/v0.0.40/jobs\nThe relevant data_parser plugin in the example URLs is \"v0.0.40\" which\nmatches the data_parser/v0.0.40 plugin. Plugin naming follows the\nnaming schema of vXX.XX.XX where the XX are numbers. The naming\nschema matches the internal naming schema for Slurm's packed binary RPC layer\nbut is not directly related. The URLs for each given data_parser plugins will\nremain a valid query target until the plugin is removed as part of SchedMD's\ncommitment to ensure release limited backwards compatibility. While it should\nbe possible to continue using any client from a prior release while the plugins\nare still supported, sites should always recompile any generated OpenAPI\nclients and test thoroughly before upgrading.Create Backups\nAlways create full backups to restore all parts of Slurm, including\nthe Mysql database, before upgrading in the event the upgrade must be reverted.\nSchedMD aims to make supported upgrades a seamless process but it is possible\nfor unexpected issues to arise and irreversibly corrupt all of the data\nkept by Slurm. If something like this happens, it will not be possible to\nrecover any corrupted data and you will be reliant on backed up data.It is recommended to prepare recovery options (file backups, disk images,\nsnapshots, database dumps) that will take you back to a known working cluster\nstate. How backups are taken is specific to how the systems integrator\ndesigned and setup the cluster and procedures are not provided here.At a minimum, back up the following:\n\nStateSaveLocation as defined in\nslurm.conf, or it can be\nqueried by calling scontrol show config | grep StateSaveLocation\nEntire slurm configuration directory, as defined by\nconfigure --sysconfdir=DIR during compilation.\nThis is usually located in /etc/slurm/\nMySQL database (if slurmdbd is configured). Usually done by calling\n\nmysqldump --databases slurm_acct_db > /path/to/offline/storage/backup.sql\n\nThis assumes that slurmdbd is not running while the dump is running.\nIf you wish to back it up while slurmdbd is running, you may use the\n--single-transaction flag with the following limitations:\n\nDatabase operations may be slower while the dump is running\nRestoring this dump will restore the database at the time the dump was\nstarted, losing any changes made during or after the dump\nCertain cluster operations may lead to an incorrect or failed dump:\n\nCreating a new database\nUpgrading an existing database\nAdding or Removing a cluster in the slurmdbd\n\nArchiving or Purging accounting data\n\n\n\n\nslurmdbd (Accounting)\nIf slurmdbd is used in your environment, it must be at the same or\nhigher major release number as the slurmctld daemon(s), and at a close enough\nversion for compatibility. Thus, when\nperforming upgrades, it should be upgraded first. When a backup slurmdbd host\nis in use, it should be upgraded at the same time as the primary.Upgrades to the slurmdbd may require significant downtime.\nWith large accounting databases, the precautionary database dump will take some\ntime, and the upgraded daemon may be unresponsive for tens of minutes while it\nupdates the database to the new schema. Sites are encouraged to use the\npurge functionality if older\naccounting data is not required for normal operations. Purging old records\nbefore attempting to upgrade can significantly decrease outage time.The non-slurmdbd functionality of the cluster will continue to operate while\nthe upgrade is in process, provided the activity does not fill up the slurmdbd\nAgent queue on the slurmctld node.  While slurmdbd is offline, you should\nmonitor the memory usage of slurmctld, and the DBD Agent queue size, as\nreported by sdiag, to ensure it does not exceed the configured\nMaxDBDMsgs in slurm.conf.\nCli commands sacct and \nsacctmgr will not work while slurmdbd is down.\nslurmrestd queries that include slurmdb in\nthe URL path will fail while slurmdbd is down.It is preferred to create a backup of the database after shutting down the\nslurmdbd daemon, when the MySQL database is no longer changing. If you\nwish to take a backup with mysqldump while the slurmdbd is still\nrunning, you can add --single-transaction to the mysqldump command.\nNote that the slurmdbd will continue to execute operations that will not be\ncontained in the dump, which may cause complications if you need to restore\nthe database to this state.The suggested upgrade procedure is as follows:\nShutdown the slurmdbd daemon(s) gracefully:\nsacctmgr shutdownor via systemd:\nsystemctl stop slurmdbd Wait until slurmdbd is fully down before\nproceeding or there may be data loss from data that was not fully saved.\nsystemctl status slurmdbd\n\nBackup the Slurm database\nVerify that the innodb_buffer_pool_size in my.cnf is greater than the\ndefault. See the recommendation in the\n\n\taccounting page.\nUpgrade the slurmdbd daemon binaries and libraries.\nInstall the new RPM/DEB\n\tpackages only on the slurmdbd system. Do not upgrade the other Slurm\n\tsystems at this time.\nStart the primary slurmdbd daemon.\n\tNOTE: If you typically use systemd, it is recommended to\n\tinitially start the daemon directly as the configured SlurmUser:\n\tsudo -u slurm slurmdbd -D\nWhen the daemon starts up for the first time after upgrading, it\n\twill take some extra time to update existing records in the database. If\n\tit is started with systemd and reaches the configured timeout value, it\n\tmay be killed prematurely potentially causing data loss. After it\n\tfinishes starting up, you can use Ctrl+C to exit, then\n\tstart it normally with systemd.\nStart the backup slurmdbd daemon (if applicable).\nValidate accounting operation, such as retrieving data through\n\tsacct or sacctmgr.\nDatabase Server\nWhen upgrading the database server that is used by slurmdbd (e.g., MySQL or\nMariaDB), usually no special procedures are required. It is recommended to use a\ndatabase server that is supported by the publisher (or that was at the time when\nthe chosen Slurm version was initially released). Database upgrades should be\nperformed while the slurmdbd is stopped and according to the recommended\nprocedure for the database used.When upgrading an existing accounting database to MariaDB 10.2.1 or\nlater from an older version of MariaDB or any version of MySQL, ensure you are\nrunning slurmdbd 22.05.7 or later. These versions will gracefully handle\nchanges to MariaDB default values that can cause problems for slurmdbd.slurmctld (Controller)\nIt is preferred to upgrade the slurmctld system(s) at the same time as slurmd\non the compute nodes and other Slurm commands on client machines and login nodes.\nThe effects of downtime on slurmctld and slurmd daemons are largely the same,\nso upgrading them all together minimizes the total duration of these effects.\nRolling upgrades are also possible if the slurmctld is upgraded first. When\nmultiple slurmctld hosts are used, all should be upgraded simultaneously.Upgrading the slurmctld involves a brief period of downtime during\nwhich job submissions are not accepted, queued jobs are not scheduled, and\ninformation about completing jobs is held. These functions will resume once\nthe upgraded controller is started.The recommended upgrade procedure is below, including optional steps for a\nsimultaneous upgrade of slurmd systems:\nIncrease configured SlurmdTimeout and SlurmctldTimeout values and\n\texecute scontrol reconfig for them to take effect.\n\tThe new timeout should be long enough to perform the upgrade using\n\tyour preferred method. If the timeout is reached, nodes may be marked\n\tDOWN and their jobs killed.\nShutdown the slurmctld daemon(s).\n(opt.) Shutdown the slurmd daemons on the compute nodes.\nBack up the contents of the configured StateSaveLocation.\nUpgrade the slurmctld (and optionally slurmd) daemons.\n(opt.) Restart the slurmd daemons on the compute nodes.\nRestart the slurmctld daemon(s).\nValidate proper operation, such as communication with nodes and a job's\n\tability to successfully start and finish.\nRestore the preferred SlurmdTimeout and SlurmctldTimeout values and\n\texecute scontrol reconfig for them to take effect.\nslurmd (Compute Nodes)\nIt is preferred to upgrade all slurmd nodes at the same time as the slurmctld.\nIt is also possible to perform a rolling upgrade by upgrading the slurmd nodes\nlater in any number of groups. Sites are encouraged to minimize the amount of\ntime during which mixed versions are used in a cluster.Upgrades will not interrupt running jobs as long as SlurmdTimeout\nis not reached during the process. However, while the slurmd is down for\nupgrades, new jobs will not be started and finishing jobs will wait to\nreport back to the controller until it comes back online.If you are upgrading the slurmd nodes separately from the controller, the\nfollowing procedure can be followed:\nIncrease the configured SlurmdTimeout value and execute\n\tscontrol reconfig for it to take effect.\n\tThe new timeout should be long enough to perform the upgrade using\n\tyour preferred method. If the timeout is reached, nodes may be marked\n\tDOWN and their jobs killed.\nShutdown the slurmd daemons on the compute nodes.\nBack up the contents of the configured StateSaveLocation.\nUpgrade the slurmd daemons.\nRestart the slurmd daemons.\nValidate proper operation, such as communication with the controller and a\n\tjob's ability to successfully start and finish.\nRepeat for any other groups of nodes that need to be upgraded.\nRestore the preferred SlurmdTimeout value and\nexecute scontrol reconfig for it to take effect.\nOther Slurm Commands\nOther Slurm commands (including client commands) do not require special\nattention when upgrading, except where specifically noted in the release notes.\nYou should also pay attention to any changes introduced in these additional\ncomponents. After core Slurm components have been upgraded, upgrade additional\ncomponents and client commands using the normal method for your system, then\nrestart any affected daemons.Customized Slurm Plugins\nSlurm's main public API library (libslurm.so.X.0.0) increases its version\nnumber with every major release, so any application linked against it should be\nrecompiled after an upgrade. This includes locally developed Slurm plugins.If you have built your own version of Slurm plugins, besides having to\nrecompile them, they will likely need modification to support the new version\nof Slurm. It is common for plugins to add new functions and function arguments\nduring major updates. See the RELEASE_NOTES file for details about these\nchanges.Slurm's PMI-1 (libpmi.so.0.0.0) and PMI-2 (libpmi2.so.0.0.0) public API\nlibraries do not change between releases and are meant to be permanently\nfixed. This means that linking against either of them will not require you\nto recompile the application after a Slurm upgrade, except in the unlikely\nevent that one of them changes. It is unlikely because these libraries must\nbe compatible with any other PMI-1 and PMI-2 implementations. If there was a\nchange, it would be announced in the RELEASE_NOTES and would only happen on\na major release.As an example, MPI stacks like OpenMPI and MVAPICH2 link against Slurm's\nPMI-1 and/or PMI-2 API, but not against our main public API. This means that at\nthe time of writing this documentation, you don't need to recompile these\nstacks after a Slurm upgrade. One known exception is MPICH. When MPICH is\ncompiled with Slurm support and with the Hydra Process Manager, it will use\nthe Slurm API to obtain job information. This link means you will need to\nrecompile the MPICH stack after an upgrade.One easy way to know if an application requires a recompile is to inspect all\nof its ELF files with 'ldd' and grep for 'slurm'. If you see a versioned\n'libslurm.so.x.y.z' reference, then the application will likely need to be\nrecompiled.Seamless Upgrades\nIn environments where the Slurm build process is customized, it is possible\nto install a new version of Slurm to a unique directory and use a symbolic link\nto point the directory in your PATH to the version of Slurm you would like to\nuse. This allows you to install the new version before you are in a maintenance\nperiod as well as easily switch between versions should you need to roll\nback for any reason. It also avoids potential problems with library conflicts\nthat might arise from installing different versions to the same directory.Last modified 15 August 2024"
        },
        {
            "title": "Navigation",
            "content": "\nSlurm Workload Manager\nVersion 24.05\n\n\nAbout\n\nOverview\nRelease Notes\n\n\n\nUsing\n\nDocumentation\nFAQ\nPublications\n\n\n\nInstalling\n\nDownload\nRelated Software\nInstallation Guide\n\n\n\nGetting Help\n\nMailing Lists\nSupport and Training\nTroubleshooting\n\n\n"
        }
    ]
}