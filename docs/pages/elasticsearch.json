{
    "url": "https://slurm.schedmd.com/elasticsearch.html",
    "sections": [
        {
            "title": "\n\nSlurm Workload Manager\n\n",
            "content": "\n\nSchedMD\n\n"
        },
        {
            "title": "Elasticsearch Guide",
            "content": "Slurm provides multiple Job Completion Plugins.\nThese plugins are an orthogonal way to provide historical job\naccounting data for finished jobs.In most installations, Slurm is already configured with an\nAccountingStorageType\nplugin \u2014 usually slurmdbd. In these situations, the information\ncaptured by a completion plugin is intentionally redundant.The jobcomp/elasticsearch plugin can be used together with a web\nlayer on top of the Elasticsearch server \u2014 such as\nKibana \u2014 to\nvisualize your finished jobs and the state of your cluster. Some of these\nvisualization tools also let you easily create different types of dashboards,\ndiagrams, tables, histograms and/or apply customized filters when searching.\nPrerequisitesThe plugin requires additional libraries for compilation:\nlibcurl development files\nJSON-C\nConfigurationThe Elasticsearch instance should be running and reachable from the multiple\nSlurmctldHost configured.\nRefer to the Elasticsearch\nOfficial Documentation for further details on setup and configuration.\n\nThere are three slurm.conf options related to\nthis plugin:\n\n\nJobCompType\nis used to select the job completion plugin type to activate. It should be set\nto jobcomp/elasticsearch.\nJobCompType=jobcomp/elasticsearch\n\n\nJobCompLoc should be set to\nthe Elasticsearch server URL endpoint (including the port number and the target\nindex).\nJobCompLoc=<host>:<port>/<target>/_doc\nNOTE: Since Elasticsearch 8.0 the APIs that accept types are removed,\nthereby moving to a typeless mode. The Slurm elasticsearch plugin in versions\nprior to 20.11 removed any trailing slashes from this option URL and appended\na hardcoded /slurm/jobcomp suffix representing the /index/type\nrespectively.\nStarting from Slurm 20.11 the URL is fully configurable and handed as-is without\nmodification to the libcurl library functions. In addition, this also allows\nusers to index data from different clusters to the same server but to different\nindices.\nNOTE: The Elasticsearch official documentation provides detailed\ninformation around these concepts, the type to typeless deprecation transition\nas well as reindex API references on how to copy data from one index to another\nif needed.\n\n\n\nDebugFlags could include\nthe Elasticsearch flag for extra debugging purposes.\nDebugFlags=Elasticsearch\nIt is a good idea to turn this on initially until you have verified that\nfinished jobs are properly indexed. Note that you do not need to manually\ncreate the Elasticsearch index, since the plugin will automatically\ndo so when trying to index the first job document.\n\n\nVisualization\n\n\nOnce jobs are being indexed, it is a good idea to use a web visualization\nlayer to analyze the data.\nKibana is a\nrecommended open-source data visualization plugin for Elasticsearch.\nOnce installed, an Elasticsearch index name or pattern has to be\nconfigured to instruct Kibana to retrieve the data. Once data is loaded it is\npossible to create tables where each row is a finished job, ordered by\nany column you choose \u2014 the @end_time timestamp is suggested \u2014 and\nany dashboards, graphs, or other analysis of interest.\n\nTesting and Debugging\n\n\nFor debugging purposes, you can use the curl command or any similar\ntool to perform REST requests against Elasticsearch directly. Some of the\nfollowing examples using the curl tool may be useful.\nQuery information assuming a slurm index name, including the\ndocument count (which should be one per job indexed):\n\n$ curl -XGET http://localhost:9200/_cat/indices/slurm?v\nhealth status index uuid                   pri rep docs.count docs.deleted store.size pri.store.size\nyellow open   slurm 103CW7GqQICiMQiSQv6M_g   5   1          9            0    142.8kb        142.8kb\n\nQuery all indexed jobs in the slurm index:\n\n$ curl -XGET 'http://localhost:9200/slurm/_search?pretty=true&q=*:*' | less\n\nDelete the slurm index (caution!):\n\n$ curl -XDELETE http://localhost:9200/slurm\n{\"acknowledged\":true}\n\nQuery information about _cat options. More can be found in the\nofficial documentation.\n\n$ curl -XGET http://localhost:9200/_cat\n\nFailure management\n\n\nWhen the primary slurmctld is shut down, information about all completed but\nnot yet indexed jobs held within the Elasticsearch plugin saved to a\nfile named elasticsearch_state, which is located in the\nStateSaveLocation. This\npermits the plugin to restore the information when the slurmctld is restarted,\nand will be sent to the Elasticsearch database when the connection is\nrestored.\nAcknowledgments\nThe Elasticsearch plugin was created as part of Alejandro Sanchez's\nMaster's Thesis.\nLast modified 6 August 2021\n"
        },
        {
            "title": "Navigation",
            "content": "\nSlurm Workload Manager\nVersion 24.05\n\n\nAbout\n\nOverview\nRelease Notes\n\n\n\nUsing\n\nDocumentation\nFAQ\nPublications\n\n\n\nInstalling\n\nDownload\nRelated Software\nInstallation Guide\n\n\n\nGetting Help\n\nMailing Lists\nSupport and Training\nTroubleshooting\n\n\n"
        },
        {
            "title": "Visualization\n\n",
            "content": "Once jobs are being indexed, it is a good idea to use a web visualization\nlayer to analyze the data.\nKibana is a\nrecommended open-source data visualization plugin for Elasticsearch.\nOnce installed, an Elasticsearch index name or pattern has to be\nconfigured to instruct Kibana to retrieve the data. Once data is loaded it is\npossible to create tables where each row is a finished job, ordered by\nany column you choose \u2014 the @end_time timestamp is suggested \u2014 and\nany dashboards, graphs, or other analysis of interest.\n\nTesting and Debugging\n\n\nFor debugging purposes, you can use the curl command or any similar\ntool to perform REST requests against Elasticsearch directly. Some of the\nfollowing examples using the curl tool may be useful.\nQuery information assuming a slurm index name, including the\ndocument count (which should be one per job indexed):\n\n$ curl -XGET http://localhost:9200/_cat/indices/slurm?v\nhealth status index uuid                   pri rep docs.count docs.deleted store.size pri.store.size\nyellow open   slurm 103CW7GqQICiMQiSQv6M_g   5   1          9            0    142.8kb        142.8kb\n\nQuery all indexed jobs in the slurm index:\n\n$ curl -XGET 'http://localhost:9200/slurm/_search?pretty=true&q=*:*' | less\n\nDelete the slurm index (caution!):\n\n$ curl -XDELETE http://localhost:9200/slurm\n{\"acknowledged\":true}\n\nQuery information about _cat options. More can be found in the\nofficial documentation.\n\n$ curl -XGET http://localhost:9200/_cat\n\nFailure management\n\n\nWhen the primary slurmctld is shut down, information about all completed but\nnot yet indexed jobs held within the Elasticsearch plugin saved to a\nfile named elasticsearch_state, which is located in the\nStateSaveLocation. This\npermits the plugin to restore the information when the slurmctld is restarted,\nand will be sent to the Elasticsearch database when the connection is\nrestored.AcknowledgmentsThe Elasticsearch plugin was created as part of Alejandro Sanchez's\nMaster's Thesis.Last modified 6 August 2021"
        },
        {
            "title": "Testing and Debugging\n\n",
            "content": "For debugging purposes, you can use the curl command or any similar\ntool to perform REST requests against Elasticsearch directly. Some of the\nfollowing examples using the curl tool may be useful.Query information assuming a slurm index name, including the\ndocument count (which should be one per job indexed):\n$ curl -XGET http://localhost:9200/_cat/indices/slurm?v\nhealth status index uuid                   pri rep docs.count docs.deleted store.size pri.store.size\nyellow open   slurm 103CW7GqQICiMQiSQv6M_g   5   1          9            0    142.8kb        142.8kb\nQuery all indexed jobs in the slurm index:\n$ curl -XGET 'http://localhost:9200/slurm/_search?pretty=true&q=*:*' | less\nDelete the slurm index (caution!):\n$ curl -XDELETE http://localhost:9200/slurm\n{\"acknowledged\":true}\nQuery information about _cat options. More can be found in the\nofficial documentation.\n$ curl -XGET http://localhost:9200/_cat\nFailure management\n\nelasticsearch_stateStateSaveLocation"
        }
    ]
}